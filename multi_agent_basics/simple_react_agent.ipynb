{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "# Set up your OpenAI API key (replace with your key or use environment variable)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from os import getenv\n",
        "\n",
        "# Initialize the language model\n",
        "llm = ChatOpenAI(\n",
        "  model=\"anthropic/claude-sonnet-4\",\n",
        "  temperature=0.2,\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key=getenv(\"OPENROUTER_API_KEY\")\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "def execute_python_code(code: str) -> str:\n",
        "    \"\"\"\n",
        "    Execute Python code safely using eval.\n",
        "    \n",
        "    Args:\n",
        "        code: Python code to execute (simple expressions only)\n",
        "    \n",
        "    Returns:\n",
        "        String containing the result of the code execution\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Basic safety: only allow simple expressions\n",
        "        if any(keyword in code.lower() for keyword in ['import', 'exec', '__', 'open', 'file']):\n",
        "            return \"Error: Code contains potentially unsafe operations\"\n",
        "        \n",
        "        # Execute the code using eval\n",
        "        result = eval(code)\n",
        "        return f\"Result: {result}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error executing code: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ü§ñ Simple React Agent with Python Code Execution\n",
            "\n",
            "Math calculation:\n",
            "[HumanMessage]\n",
            "What is 25 * 37 + 100?\n",
            "[AIMessage]\n",
            "  [TOOL CALL] name: execute_python_code, args: {'code': '25 * 37 + 100'}, id: toolu_01BKRy2Fi3WHk3ZYG69LMb7r\n",
            "I'll calculate that for you.\n",
            "[ToolMessage]\n",
            "  [TOOL RESULT] execute_python_code: Result: 1025\n",
            "[AIMessage]\n",
            "The answer is 1025.\n",
            "\n",
            "To break it down:\n",
            "- 25 √ó 37 = 925\n",
            "- 925 + 100 = 1025\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create the React agent with our single tool\n",
        "memory = MemorySaver()\n",
        "agent = create_react_agent(\n",
        "    llm, \n",
        "    tools=[execute_python_code],\n",
        "    checkpointer=memory\n",
        ")\n",
        "\n",
        "# Test the agent\n",
        "config = {\"configurable\": {\"thread_id\": \"simple-math\"}}\n",
        "\n",
        "print(\"ü§ñ Simple React Agent with Python Code Execution\\n\")\n",
        "\n",
        "# Test 1: Simple math\n",
        "result = agent.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"What is 25 * 37 + 100?\")]},\n",
        "    config=config\n",
        ")\n",
        "\n",
        "print(\"Math calculation:\")\n",
        "for i, msg in enumerate(result[\"messages\"]):\n",
        "    # Print message type for clarity\n",
        "    print(f\"[{type(msg).__name__}]\")\n",
        "    # If the message is an AIMessage with tool calls, print tool call details\n",
        "    if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
        "        for tool_call in msg.tool_calls:\n",
        "            print(f\"  [TOOL CALL] name: {tool_call['name']}, args: {tool_call['args']}, id: {tool_call['id']}\")\n",
        "    # If the message is a ToolMessage, print which tool and the result\n",
        "    if hasattr(msg, \"name\") and hasattr(msg, \"content\"):\n",
        "        if getattr(msg, \"name\", None):\n",
        "            print(f\"  [TOOL RESULT] {msg.name}: {msg.content}\")\n",
        "        else:\n",
        "            print(msg.content)\n",
        "    else:\n",
        "        print(msg.content)\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='What is 25 * 37 + 100?', additional_kwargs={}, response_metadata={}, id='f26df2f1-f12c-49a1-862c-2963a7807d20'),\n",
              "  AIMessage(content=\"I can help you calculate that! Let me work through this step by step:\\n\\n25 √ó 37 + 100\\n\\nFirst, I'll multiply 25 √ó 37:\\n25 √ó 37 = 925\\n\\nThen I'll add 100:\\n925 + 100 = 1,025\\n\\nTherefore, 25 √ó 37 + 100 = 1,025\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 91, 'prompt_tokens': 388, 'total_tokens': 479, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'anthropic/claude-sonnet-4', 'system_fingerprint': None, 'id': 'gen-1752340456-dki1qLOugHhhk6vAMgvE', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--d04c6e63-542e-4686-a939-0f385c62d216-0', usage_metadata={'input_tokens': 388, 'output_tokens': 91, 'total_tokens': 479, 'input_token_details': {}, 'output_token_details': {}}),\n",
              "  HumanMessage(content='What is 25 * 37 + 100?', additional_kwargs={}, response_metadata={}, id='db69e6b8-4632-4563-97b5-b89e95f9ce4c'),\n",
              "  AIMessage(content='I can calculate that for you:\\n\\n25 √ó 37 + 100\\n\\nFirst, multiply 25 √ó 37:\\n25 √ó 37 = 925\\n\\nThen add 100:\\n925 + 100 = 1,025\\n\\nSo 25 √ó 37 + 100 = 1,025', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 77, 'prompt_tokens': 495, 'total_tokens': 572, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'anthropic/claude-sonnet-4', 'system_fingerprint': None, 'id': 'gen-1752340633-sGQG0g5Erq8ggBZgGFh0', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--9d9d2fa2-bf95-445a-a8df-e7c9e48807ee-0', usage_metadata={'input_tokens': 495, 'output_tokens': 77, 'total_tokens': 572, 'input_token_details': {}, 'output_token_details': {}})]}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "@tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"\n",
        "    Get the weather for a given city.\n",
        "    \"\"\"\n",
        "    return f\"The weather in {city} is sunny and 68¬∞F.\"\n",
        "\n",
        "\n",
        "second_react_agent = create_react_agent(\n",
        "    llm, \n",
        "    tools=[get_weather],\n",
        "    checkpointer=memory\n",
        ")\n",
        "\n",
        "second_react_agent.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"What is 25 * 37 + 100?\")]},\n",
        "    config={\"configurable\": {\"thread_id\": \"simple-math-2\"}}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multi-Agent Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "from langchain_core.messages import HumanMessage, ToolMessage\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.types import Command\n",
        "\n",
        "# Define a tool for agent1 that represents a handoff to agent2\n",
        "@tool  \n",
        "def handoff_to_agent2(message: str) -> str:\n",
        "    \"\"\"\n",
        "    Handoff to agent2 with a message.\n",
        "    Use this tool when you need agent2 to help with weather-related queries.\n",
        "    \"\"\"\n",
        "    return f\"Transferred to agent2: {message}\"\n",
        "\n",
        "# Define a tool for agent2 that represents a handoff to agent1  \n",
        "@tool\n",
        "def handoff_to_agent1(message: str) -> str:\n",
        "    \"\"\"\n",
        "    Handoff to agent1 with a message.\n",
        "    Use this tool when you need agent1 to help with code execution or mathematical calculations.\n",
        "    \"\"\"\n",
        "    return f\"Transferred to agent1: {message}\"\n",
        "\n",
        "system_prompt_agent_1 = \"\"\"\n",
        "You are Agent 1, a helpful assistant that can handoff to other agents. You can execute python code.\n",
        "\n",
        "The agents are:\n",
        "- Agent 1 (you) who can execute python code\n",
        "- Agent 2 who can get the weather in any city in real time\n",
        "\n",
        "If you need another agent to help you, you can handoff to them using the appropriate handoff tool.\n",
        "\"\"\"\n",
        "\n",
        "system_prompt_agent_2 = \"\"\"\n",
        "You are Agent 2, a helpful assistant that can handoff to other agents. You can get the weather in any city in real time.\n",
        "\n",
        "The agents are:\n",
        "- Agent 1 who can execute python code\n",
        "- Agent 2 (you) who can get the weather in any city in real time\n",
        "\n",
        "If you need another agent to help you, you can handoff to them using the appropriate handoff tool.\n",
        "\"\"\"\n",
        "\n",
        "agent1 = create_react_agent(\n",
        "    llm,\n",
        "    prompt=system_prompt_agent_1,\n",
        "    tools=[handoff_to_agent2, execute_python_code],\n",
        "    checkpointer=memory\n",
        ")\n",
        "\n",
        "agent2 = create_react_agent(\n",
        "    llm,\n",
        "    prompt=system_prompt_agent_2,\n",
        "    tools=[handoff_to_agent1, get_weather],\n",
        "    checkpointer=memory\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Conversation Graph Visualization:\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPIAAAEICAIAAADqdD44AAAAAXNSR0IArs4c6QAAGQlJREFUeJzt3XdcE/f/B/DPhSSEkTAChA0CUlQQVFDEVlxV6967otWKWlsH1jpqravaunBWUSvDunH/WqvVUls3KpWpRYggU1YGkAG57x/nL7VtALEJd/nwfj7443Ij975HXnxy98kNgiRJBABeWHQXAID+QawBhiDWAEMQa4AhiDXAEMQaYIjd5BxFubXlhaoaeX2L1MNcbC5hKWALnbhCZ1O6a2mapp58nl1bVapS1GjorkVvOFzC0ppt52xqI+I2PifRSL+1WqU5v68QEQTfhmNu2fQ/AN44XFZZkYIkkZUt+52RdnSX05hisSLp5AuuGUvkaU7W4/O7BJvHKstXEAQpdOKGDhI2MmeDsVarNOe+LQzsJXT0NDNYnUbpwbUygkQ9RzE02SV5it/OlveZ6MThYruHeefSC76VSbeBtg3N0OCWn98Hmdatcx+7OjV5/1ol3YXoUKfWnN5ZMCDCBeNMI4S6DbSvLFGn35I0NIPujS/KrUUEAZluSGAv27QbElLDuO/3+1crA8Nt6K6iJQT2sn30m6ShfQ3dsS4vVAlsOAYuzIhxeSakBsmq6ugu5J9ePFdZ2TdxOIUHS2uOtKJOpdB9QKw71jXyerNWf4zYODM+u0bKuN6hWlm9mUVr+eAsBCY10ubEGgCjBrEGGIJYAwxBrAGGINYAQxBrgCGINcAQxBpgCGINMASxBhiCWAMMQawBhlrLaTGAaWRy2c5dmx49eiCVSry9fYcOHtW//2B9vTlDW+vVa5b+8OO5N1hw5Oh3C4sKDFAR+K9yc59OmDRE+3Lt2mUPH96bO2fR+nXb3N08N3y9Kvn+HX2ti6Gt9ePHGSEh3Zu7VHFxUVUVEy9aAQihx08ytMOPHj28l3x7R/SBgIAghFBQYJebt67//vsvwV266WVdNMf69p0bx4/HZz1Ot7W18/cPnDXzY6HQrnffYITQps1rv9277cK5JLlcfvLU4bv3bonFT4W2dmFh4R9Mn8Pj8RBCq75cYmJiIhI5HTsePy0iMjZuH0Jo8pThPXqEr1uzhd5NMxa3bv127ZefHqU+lEol7fz8339/ZqegYGrS+QuJJ04kSGXS0NC3Z0yfO2HSkM9XrO/bZwBCKD39UVx8TFZWupW1TffQdyKmzrKwsEAInTl7IuHwgeitMatWLxGLc7y8fMaOmTxwwNBDsXvjEw4ghHr3DZ47Z+HoURPjDp1ycnKhVkQQhIO9qKa2Rl8bRedOyJM/s5Ytn9+pU0jsd6c++XjJ06dPvv7mS4TQpR9uIIQ+XbzywrkkhNDpM8eOHI0dP+79r9ZHR0bOT/r1Slx8DPUOHA4nJzc7Jzd7/dqtw4eN2bA+GiH0/eFzkOnXpFAo1m/4XKlULv1s9Vfro93dPVd8vrCiohwhlJmVvi16Q3h4v4S407169luzbhlCiMViIYSeF+QvXjJXoVTs2nlo7erNOTl/Llw0q66ujvpE5HLZjp3ffBq18trP98J79vtm05qSkuLp02ZPGD9VJHL85Wry2DGTWSyWu7snh/PyCqyCwufZT5/4tvXT13bR2VqnpabweLwpkz9gsVgikaPfW+1zcrP/Pdu4sVPCe/b18Gjzcqm0P+7euxk56xPqv7y4uHDvngSq8QbNxePxDsQcMzMzs7KyRgi18/M/d/5UalpKeM++ly9ftLUVTp82m81mh4X1fPJnZkZGKrXUzz//yGFz1q7eTC21OGrlxMlDf7+R1Cu8H0JIrVZHTJ3Vvn0AQmhA/yGHYvdmZz8WiRwbqkGj0WzZss7e3mHI4FH62i46Y+0fEKRQKJatWBDcpVv37j1dXdy0X3+v4nA495Jvbfx6VfbTJ1STYGPz15X0Hu5tINP/RU1N9YGDu1L+uF9eXkaNoY5PcnKz27XzZ7NfJqTnO33j4vdTw+npf/j5daAyjRBydHRydnZ9lPqQijVCyM+vAzXA5wsQQnK5rKG119bWrl2/vKS0eEf0QT1+jnTG2ret38YNO65fvxqzf+eeb7d16dx1WkSkv3/gP2aL2b/zhx/ORkbODwnuLhI5Hji4+9VOEq6pEdxjibFKSornL5zZuVPXlSu+at8+gCCIdweEUpPkcpmDw19NrDbE1KSsxxnUIZBWZUW5dpggiNdc+9Lln6hVqs2b9jg4iPSxQS/RfMjYrWtYt65h06fNvn//TuLpo8tXLDideOXVGUiSvHAxcczoSUMGj6TGNPKvD5or6dcrKpVq6WerzczMtO00xdSUV6dWa1+WV5Rph22FdgEBQdOnzX71rawE1qg5FArFkqXzzHhm3+6O1/v3LZ2xTkm5r1Qpu3UNs7OzHzBgiKOj84JFs4pLiuztHLTzqNXq2tpau/8fo1Kpbt66Tl/JuJFKJXy+gMo0QujX61e1k1xc3P78M0v78saNJO2wt1fby1f+L7BjZ+oIEiEkFue4uro3a9Wbt6xFCK1ft80Q+5B09oSkpf/x5eolFy6erqqqzMhMO33mmJ2dvaPIydTU1N7eITn59sOUZOqQ+cdL5wsKn0skVd9sXhPgHySTSaurq//9hm7ungihpKQrGZlpdGyQ8fHyalteXnb+QmJdXd2duzcfPLhrZWVdWlqMEOoRFv7sWe6Ro7EkSd5Lvp2amqJdasyYyRqNZteeLQqFIj//2b6YHR/MHK/zcP9Vrq7u5eVlv/+elJ//LCMj9eq1nwYOGJqXL36Ykkz9ZervU6OztR43dkpVVeWu3Zu3bvuKy+X26T1g29YY6hhl8qQPDsXuvXvv5tEjF1eu+Gr3ni3Tpo/h8Xhz5ywKCgq+e/fmyNH94mIT//GGLs6uVBepf4fAbVv30bRZxqRvnwHPnuXEJ+zfFr0hJDj0syVfHjsef+RorEwmXTB/6cgR4+LiY06cPNy+fcDMmfM+mjeN6pIT8AUHDxw/diwucs6UvDyxn1+HTxevbLJ7LrTb2wH+QStXLdZ2csfs3/nqDG5uHvH/+kzfjO5bS979qUKlQIG9Grx1H/jh4PPwUXaOnszqhDm57XmXd+3s3fRQVV1dnVic4+PjS73MzEqf+1HE/n1HtGNod273s8EznG1EOm4/xtBzQgDtUtNSPoyctH3H18XFRRkZqdu3b+zQoaO3d1u663ot+tkJGTqsl87x9fX1LBaroe6ewwlnX+020qPU1JTlKxbonKRSqTgcjs6SPDy9du34zhD1GKNOQcFRi1b8eOn8BzPHWVryg7uEzp694DV77minn1jHxBx5g6UMlGmEUEBAUEMlVVfLLSwsdU5imzD0xC+6DBk8Utuvalz080E6OTrr5X30iIElgRYD+9YAQxBrgCGINcAQxBpgCGINMASxBhiCWAMMQawBhiDWAEO6Y82zMNEw71majMLhEqY8xjUKfFt2nVr3M93ww+WZcHm6z1HR/cEIHbmleQoDV2XE6tSakjyFjSPjHuzJt2WXFSrprqIl1Mjq5FVqCyvdZ3/ojrWzN69OVS+XqHVOBTmPZP7dBXRXoUP7roK8TDndVbSEnEeyDmENfgS6Y00QxHvTnW6cKVHUMO5BsbQTZ8jyMuXvjLSnuxAdbETczn2sk04W0V2IYT2+L6koUnQbKGxoBt1Xx1AkZeoT2/LbBPCt7bnwrGiWCaosUalq66peqIZFOrNYzD3z+HGyLO2mxMaRJ3LnISM5Q/p1mLBReZFSVVtfI60bPMOpkTkbizUl/bakNE9ZTevzvVUqVUFBQZs2bWiswYxvYmbOcnA39Qnk01jGa5KUqXNS5dKKOlllHd216I2FFZtnzhJ5mHr56z5jXqvpWDOBWCyOiopKTNTP9ZsAe4zrogLgv4NYAwxBrAGGINYAQxBrgCGINcAQxBpgCGINMASxBhiCWAMMQawBhiDWAEMQa4AhiDXAEMQaYAhiDTAEsQYYglgDDEGsAYYg1gBDEGuAIYg1wBDEGmDIOGJNEIRIJKK7CmA0jCPWJEmWlJTQXQUwGsYRawCaBWINMASxBhiCWAMMQawBhiDWAEMQa4AhiDXAEMQaYAhiDTAEsQYYglgDDEGsAYYg1gBDEGuAIUY/bnTKlClVVVUmJiZKpbKiokIkErFYrNra2suXL9NdGmA0RrfWY8eOraioKCgoKCsr02g0RUVFBQUFJiYmdNcFmI7RsR4+fLi7u/urY0iS7N69O30VAePA6FgjhMaNG2dqaqp9KRKJIiIiaK0IGAGmx3rUqFEuLi7alz169PDw8KC1ImAEmB5rhNCkSZOoBtvV1XXq1Kl0lwOMgBHEesSIEa6urlRT7ebmRnc5wAiw/8vCKoWmrECpqNXorx7dRvSPvHTp0jtdxuSkVRt0RQRCfBu2jYhrwiYMuiJgUG/eb33lcHFOarVjG3MCowCYmrPKC5UEC7XrKggKt6a7HPCG3iTW9fXkmd0FPp0E3h0FhqmKfrculNg4cEL629JdCHgTbxLrM7sL2oVau/hYGKYkprh1odTBlRvUC9ps49PsQ8bc9GpLaw72mUYIdR/qkJUsq69j7skFoCHNjnVZgZJr1lp+vtZoyIpiFd1VgGZrdqwVNfXWdlzDFMM49i48aUUd3VWAZmt2rNVKsq6+tXwvK2s1TD7DETTECH6OAaC5INYAQxBrgCGINcAQxBpgCGINMASxBhiCWAMMQawBhiDWAEMQa4AhzGOt0WgOxe7t3Tf45Knv6a4FtBzcYj1y9LuFRQXUsERS9dnSj3+6fJHFwm0zQeOw+ryLi4uqqiq1L3+8dL6+vj5m3xG4v1lr85+uPH9NublPz1849eDhveLiQk8Pr0GDRgwfNoaalJGRGr194/OCvICATlOnzNwbs92rjc/CBcsQQhUV5Xu+3ZqW/odCoQgJ6T51ykw3Nw+E0JmzJxIOH4jeGrNq9RKxOMfLy2fsmMkDBwx9mJK8KGo2QmjylOE9eoSvW7OlR1j4uLFToKluhVoi1rv3bCkuLly0aAVBEHl54u07vhaJnEK79VAoFMs/X/iWb7s1qzdLZZLo7RsrKsq8vdoihOrr6xdGRVZXyz9d/EVbn7eOHY+f+1HE3r2HXZxdORyOXC7bsfObT6NWtmvnn3D44Deb1nQKCukUFLxhffSyFQu+P3zO2ckFIUT9G4BWqCVaspUrN2zatKdzp5BOQcHDh415y7fd3Xs3EUK37/wukVRFzprv6Ojk29bvw5nzSkqKqUVSU1Py8sTLl63t1jXM1lY4Z/YCgZV1YuIRaqparY6YOqt9+wCCIAb0H0KSZHb24xbYEGAsWqK1RiR5+vSxO3dv5Oc/o0Y4ObkghHJzsy0tLb28fKiRnYKC+fyXd2hITUvhcDidO4VQLwmCCArs8sejB9q39PPrQA1Qi8jlspbYEGAkDB5rjUazdPl8tVr14cx5QUHBfEv+x/NnUJNkcpm5+d+uYLe2tqEG5HKZWq3u3TdY51Qq6IauHBgvg8f6yZ9ZWVnpmzft6dK5KzVGLpfZ2zkghHimPJXqb9d1l5e/oAaEQjszM7P167a9OtWEBR0a4LUYPNYSSRVCiMoxQkgszhGLc9p4eiOEXFzcqqoqKyrKbW2FCKGHKck1NTXUbN7evrW1tQ4Oji7OrtSYwqICayubhtcDwF8Mfsjo6eHFZrOPn0iQyqR5eeKduzaFBIcWlxQhhEK7vW1iYrJz16bq6urnBfkJCQfs7V+mv0vnrl27hm3evLakpFgiqTp77uTsOe9funS+8XW5uXsihJKSrmRkpiGEHj/JfJiS/DAlmSTJgoJ8avgf3w8ASwZvrUUixxXL18XFxwwf0cfFxW3FsrXlFWUrv1gcMX1M3KFTCxcsO/jdntFj+7dt6xcxddbOXZvYbA614Ib10ecvJK5ZtywjI9XNzaNfv/dGjZrQ+LpcnF0HDhh6KHavf4fAbVv3bd/xdWZmGjXp3PlT586fQggdO3JRJHI09FYDejX7HnzXjpdaOfB8O+vnppIFhc/5fIGAL6CeCzNkWPgH0+aMHj1RL2/+3/16stgvxNIn0JLuQkDztEgHXwMkkqq5H0X4ePvOmPGRjY3twYO7WQSrV693aSwJ4IHOH5atrKw3frWdJMkvVi2OjJwsk0l374oVCu1oLAnggc7WGiHUrp3/1i176a0B4AdOAwIYglgDDEGsAYYg1gBDEGuAIYg1wBDEGmAIYg0wBLEGGIJYAww1O9bm/FZ0kYqZhQmHC//5xqfZnxnfhl36TGGYYhjnWZZc6NRaHkKJk2bH2s3XvEaqNkwxzFL1QmXvamppTfPZYOANNDvWAiHHtzM/6USRYephCo2GTDpR1GuMPd2FgDfR7KtjKE8eyh9crWzbWWDnzMPpEegEC0nLVbIK9e2LLyK+8ISm2ki9YawRQi8KFKm/SavK1LJyg++TaEhSrVabcg2+m2tuxTFhI2dvXuh7QkOvCxjOm8e6JYnF4qioqMTERLoLAcYBeq8AhiDWAEMQa4AhiDXAEMQaYAhiDTAEsQYYglgDDEGsAYYg1gBDEGuAIYg1wBDEGmAIYg0wBLEGGIJYAwxBrAGGINYAQxBrgCGINcAQxBpgCGINMASxBhgyjlgTBOHl5UV3FcBoGEesSZLMycmhuwpgNIwj1gA0C8QaYAhiDTAEsQYYglgDDEGsAYYg1gBDEGuAIYg1wBDEGmAIYg0wBLEGGIJYAwxBrAGGINYAQ4x+3GhkZGR1dTWLxVIoFPn5+d7e3iwWS6lUHj9+nO7SAKMx+pnewcHB+/bt077MyspCCDk4ONBaFDACjN4JmTBhgpub26tjSJIMCgqiryJgHBgdaz6fP2jQIIIgtGOcnJwmTpxIa1HACDA61gih8ePHu7q6al927NgxICCAzoKAMWB6rAUCwaBBg6hhJyenSZMm0V0RMAJMjzVCaOLEiR4eHgghf39/f39/ussBRqB5PSHScjXBIl5jRv3iDeo/+uzZs6OGTZZV1rX42hFBIEtrRncZgX94rX7rwpzaB9cqxek1Tl5m8gp1ixTGIEJn08KcWp8gy56j7NgcI/h+A03H+llmze0fynsMFwnsOK92SrQqKkV9RbHySkLhjDVtTM1N6C4HNKGJWIszqu9drhw43bWReVoPkiTj1zydt9WH7kJAE5r4Sn34S1Xfyc4tVQzTEQTRe7zjb2fL6C4ENKGxWEvK1dJyNYcLe5N/EQi5zzKr6a4CNKGxyFa9ULu0NW/BYoyAtT3X1NyEyeeHgSZiTWqQXEJDhxrDlYgVrfbQ2VjADgbAEMQaYAhiDTAEsQYYglgDDEGsAYYg1gBDEGuAIYg1wBDEGmAIYg0whE+sp88YF719I91VAEbAJ9YAaEGsAYYYcUF1XV3dwe/23L7ze2lpsb9/0Mjh40JD36YmjRjVb/q02RJJVVx8jJmZWUhw93kfLRYK7RBCYnHOxq9XPcvLDQoKnjplJt0bARiEEa31jp3fnEo8MnLE+CPfXwjv2XfV6iW/Xr9KTeJwOMePx7NYrLNnrsYdSkxNS4mN24cQUqvVny372N5eFPvdqcgPPzl2PL68HK7FAi/RH2ulUvnT5YuTJk4bNnS0lcBq0HvD+/YZGJ+wXzuDi4vblMkf8C35QqFdSHD3J08yEULXf7tWWlry0dwokcjR09Prk4+XyOUyWrcDMAj9sX7yJFOlUoUEd9eOCQrskpOTLZFKqJe+vu20k/h8QXW1HCFUUJDP4/EcHZ2o8UKhnYODqMVrBwxF/7411cp+PH/GP8ZXVpRbCayo673/vZRUKjEz+9t1lqamPANXCowG/bEW2tkjhKIWrXBx+dutrB0cHBtZSiCwqq2teXVMTQ1cEA5eoj/Wri7upqamCKFOQcHUmMrKCpIkzc0bu+jdUeSkUChycrK9vHwQQtnZT8rKXrRUyYDp6N+3Njc3nxYRGZ+wPzU1RaVS/Xr96uIlc5v8vTAsLJzL5W7euk6hUJSVvVizbplAYNVSJQOmo7+1RghNGD/V29v3yLHYBw/uWlhYdmjfMSrq88YXsbS0/Gp9dEzMjiHDwnk83qwPP/n56o8tVS9gusbuwSfOqEm5XtV3Itys7G/ivsyetw1uw8do9O+EAKB3+twJiVo8h/qt5B/q6+tJRLJNdK/rcMJZKytrfdVw5Gjs0aOxuqcRBGrgq+nA/mMiUWMdL8C46DPWy5etValVOicplUqqu+Pf9JhphNDQoaN79+6vc5JMKuULBDonUSeZAGzoM9ZMCAffks+35Ouc5OQIBwmtBexbAwxBrAGGINYAQxBrgCGINcAQxBpgCGINMASxBhiCWAMMNRZrgkVaWnFasBjj4ORlBg+wY7jGYm0r4uY/hiup/qayRKmsqYcH2DFcY7Hm23CETlxFTX0L1sN0khcqzw7wCFama2LfOqS/zZWEgpYqhulqpOqbF0rDhtB/RhdoXGNXx1BK8xSXEorDhoms7Lg8c5OWKoxZZJXqyhLlb4klM9e1YcND4Bmv6VgjhCpLVMk/V4ozqgW2HEm5ukUKYxAHN56kTOUdaPH2MHu6awGv5bViraWo1hCtsKkiSdPW+jVlpJoXawCMQitsewH+INYAQxBrgCGINcAQxBpgCGINMPQ/Lm5NIJVkf8cAAAAASUVORK5CYII=",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Example of a multi-agent workflow using LangGraph's Command-based handoff pattern\n",
        "\n",
        "from typing import Literal, Annotated, TypedDict\n",
        "from langgraph.types import Command\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "# Define the state for the conversation (shared message list)\n",
        "class ConversationState(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "def agent1_node(state: ConversationState):\n",
        "    \"\"\"Agent 1 can execute Python code and handoff to agent 2\"\"\"\n",
        "    num_message_in_state = len(state[\"messages\"])\n",
        "    # print(\"PRINTING STATE MESSAGES IN AGENT 1\")\n",
        "    # for msg in state[\"messages\"]:\n",
        "    #     print(msg)\n",
        "    # print(\"PRINTING STATE MESSAGES IN AGENT 1 DONE\")\n",
        "    response = agent1.invoke({\"messages\": state[\"messages\"]})\n",
        "    # print(\"PRINTING RESPONSE IN AGENT 1\")\n",
        "    # for msg in response[\"messages\"][num_message_in_state:]:\n",
        "    #     print(msg)\n",
        "    # print(\"PRINTING RESPONSE IN AGENT 1 DONE\")\n",
        "    \n",
        "    # Check if any handoff tools were called\n",
        "    for idx, message in enumerate(response[\"messages\"][num_message_in_state:]):\n",
        "        if hasattr(message, 'tool_calls') and message.tool_calls:\n",
        "            for tool_call in message.tool_calls:\n",
        "                if tool_call.get('name') == 'handoff_to_agent2':\n",
        "                    # Route to agent2\n",
        "                    tool_call_id = tool_call.get('id')\n",
        "                    tool_result_message = ToolMessage(\n",
        "                        content=f\"Successfully transferred to agent2\",\n",
        "                        tool_call_id=tool_call_id\n",
        "                    )\n",
        "                    return Command(\n",
        "                        goto=\"agent2\",\n",
        "                        update={\"messages\": [*response[\"messages\"][num_message_in_state:num_message_in_state + idx], message, tool_result_message]}  # Only pass everything before the handoff and the handoff message and the tool result message\n",
        "                    )\n",
        "    \n",
        "    # No handoff needed, end the conversation\n",
        "    return {\"messages\": response[\"messages\"]}\n",
        "\n",
        "def agent2_node(state: ConversationState):\n",
        "    \"\"\"Agent 2 can get weather and handoff to agent 1\"\"\"\n",
        "    num_message_in_state = len(state[\"messages\"])\n",
        "    # print(\"PRINTING STATE MESSAGES IN AGENT 2\")\n",
        "    # for msg in state[\"messages\"]:\n",
        "    #     print(msg)\n",
        "    # print(\"PRINTING STATE MESSAGES IN AGENT 2 DONE\")\n",
        "    response = agent2.invoke({\"messages\": state[\"messages\"]})\n",
        "    # print(\"PRINTING RESPONSE IN AGENT 2\")\n",
        "    # for msg in response[\"messages\"][num_message_in_state:]:\n",
        "    #     print(msg)\n",
        "    # print(\"PRINTING RESPONSE IN AGENT 2 DONE\")\n",
        "    # Check if any handoff tools were called\n",
        "    for idx, message in enumerate(response[\"messages\"][num_message_in_state:]):\n",
        "        if hasattr(message, 'tool_calls') and message.tool_calls:\n",
        "            for tool_call in message.tool_calls:\n",
        "                if tool_call.get('name') == 'handoff_to_agent1':\n",
        "                    # Route to agent1\n",
        "                    tool_call_id = tool_call.get('id')\n",
        "                    tool_result_message = ToolMessage(\n",
        "                        content=f\"Successfully transferred to agent1\",\n",
        "                        tool_call_id=tool_call_id\n",
        "                    )\n",
        "                    return Command(\n",
        "                        goto=\"agent1\",\n",
        "                        update={\"messages\": [*response[\"messages\"][num_message_in_state:num_message_in_state + idx], message, tool_result_message]}  # Only pass everything before the handoff and the handoff message and the tool result message\n",
        "                    )\n",
        "    \n",
        "    # No handoff needed, end the conversation\n",
        "    return {\"messages\": response[\"messages\"]}\n",
        "\n",
        "# Build the graph\n",
        "graph = StateGraph(ConversationState)\n",
        "graph.add_node(\"agent1\", agent1_node)\n",
        "graph.add_node(\"agent2\", agent2_node)\n",
        "\n",
        "# Set the entry point\n",
        "graph.set_entry_point(\"agent1\")\n",
        "\n",
        "# Compile the graph\n",
        "conversation_graph = graph.compile()\n",
        "\n",
        "# Try to visualize the conversation graph using IPython display, similar to the deep_research example\n",
        "try:\n",
        "    from IPython.display import Image, display\n",
        "\n",
        "    png_bytes = conversation_graph.get_graph().draw_mermaid_png()\n",
        "\n",
        "    with open(\"conversation_graph.png\", \"wb\") as f:\n",
        "        f.write(png_bytes)\n",
        "\n",
        "    print(\"üìä Conversation Graph Visualization:\")\n",
        "    display(Image(\"conversation_graph.png\"))\n",
        "except Exception as e:\n",
        "    print(\"Could not visualize the conversation graph:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ü§ñ Multi-Agent Network with Command-based Tool Handoffs\n",
            "\n",
            "üìù Conversation Flow:\n",
            "üßë‚Äçüí¨ Human: Whats is the temperature in Paris times 1243435\n",
            "\n",
            "ü§ñ AGENT1: Successfully transferred to agent2\n",
            "\n",
            "ü§ñ AGENT2: Successfully transferred to agent1\n",
            "\n",
            "ü§ñ AGENT1: The current temperature in Paris is 68¬∞F, and when multiplied by 1243435, the result is **84,553,580**.\n",
            "\n",
            "‚úÖ Conversation completed!\n"
          ]
        }
      ],
      "source": [
        "import uuid\n",
        "import time\n",
        "\n",
        "# Example usage: start a conversation and stream events\n",
        "print(\"ü§ñ Multi-Agent Network with Command-based Tool Handoffs\\n\")\n",
        "\n",
        "initial_message = \"Whats is the temperature in Paris times 1243435\"\n",
        "\n",
        "initial_state = {\"messages\": [HumanMessage(content=initial_message)]}\n",
        "initial_state\n",
        "\n",
        "# Stream the conversation\n",
        "stream = conversation_graph.stream(\n",
        "    initial_state, \n",
        "    config={\n",
        "        \"recursion_limit\": 10, \n",
        "        \"configurable\": {\"thread_id\": f'{str(uuid.uuid4())}-{time.time()}'}\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"üìù Conversation Flow:\")\n",
        "print(f'üßë‚Äçüí¨ Human: {initial_message}')\n",
        "for event in stream:\n",
        "    # Print the agent and its latest message, and also show tool calls if present\n",
        "    for agent_name, agent_response in event.items():\n",
        "        if \"messages\" in agent_response:\n",
        "            last_message = agent_response[\"messages\"][-1]\n",
        "            print(f\"\\nü§ñ {agent_name.upper()}: {last_message.content}\")\n",
        "            # Print tool calls if present in the last message\n",
        "            if hasattr(last_message, \"tool_calls\") and getattr(last_message, \"tool_calls\", None):\n",
        "                for tool_call in last_message.tool_calls:\n",
        "                    print(f\"    üõ†Ô∏è [TOOL CALL] üè∑Ô∏è: {tool_call.get('name')}, üìù: {tool_call.get('args')}, üÜî: {tool_call.get('id')}\")\n",
        "\n",
        "print(\"\\n‚úÖ Conversation completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['agent1']"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(event.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content='Whats is the temperature in Paris times 1243435', additional_kwargs={}, response_metadata={}, id='74728fd6-6f0f-498b-a37f-fb321d6706c4'),\n",
              " AIMessage(content=\"I'll help you get the temperature in Paris and then multiply it by 1243435. Let me first get the current temperature in Paris by handing off to Agent 2.\", additional_kwargs={'tool_calls': [{'id': 'toolu_01HS3wFrci9d4EG4nkefS5nL', 'function': {'arguments': '{\"message\": \"Please get the current temperature in Paris\"}', 'name': 'handoff_to_agent2'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 101, 'prompt_tokens': 589, 'total_tokens': 690, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'anthropic/claude-sonnet-4', 'system_fingerprint': None, 'id': 'gen-1752340920-C4RHzQfDaOozwCy6KkTo', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--dbec40ed-b8db-44d2-b26c-7a93bea815c1-0', tool_calls=[{'name': 'handoff_to_agent2', 'args': {'message': 'Please get the current temperature in Paris'}, 'id': 'toolu_01HS3wFrci9d4EG4nkefS5nL', 'type': 'tool_call'}], usage_metadata={'input_tokens': 589, 'output_tokens': 101, 'total_tokens': 690, 'input_token_details': {}, 'output_token_details': {}}),\n",
              " ToolMessage(content='Successfully transferred to agent2', id='61671fb4-e6d8-4f45-b0cd-dd29e695bb60', tool_call_id='toolu_01HS3wFrci9d4EG4nkefS5nL'),\n",
              " AIMessage(content='Wait, I am Agent 2! Let me get the weather in Paris first:', additional_kwargs={'tool_calls': [{'id': 'toolu_01CetGD8z7VFSAfvREi7YWUy', 'function': {'arguments': '{\"city\": \"Paris\"}', 'name': 'get_weather'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 71, 'prompt_tokens': 677, 'total_tokens': 748, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'anthropic/claude-sonnet-4', 'system_fingerprint': None, 'id': 'gen-1752340930-2dzmKTMHwtRywXUf3D1E', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a4bd6e75-1349-4c3b-93d4-dfbf213fdea8-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'Paris'}, 'id': 'toolu_01CetGD8z7VFSAfvREi7YWUy', 'type': 'tool_call'}], usage_metadata={'input_tokens': 677, 'output_tokens': 71, 'total_tokens': 748, 'input_token_details': {}, 'output_token_details': {}}),\n",
              " ToolMessage(content='The weather in Paris is sunny and 68¬∞F.', name='get_weather', id='f37f09ca-4018-4e64-a139-b940a0531788', tool_call_id='toolu_01CetGD8z7VFSAfvREi7YWUy'),\n",
              " AIMessage(content='Now I need to multiply 68¬∞F by 1243435. Let me hand this calculation off to Agent 1:', additional_kwargs={'tool_calls': [{'id': 'toolu_01YQqA1AGm3eFJi9CMMXWiUJ', 'function': {'arguments': '{\"message\": \"Please calculate 68 times 1243435. The temperature in Paris is currently 68¬∞F and I need to multiply it by 1243435.\"}', 'name': 'handoff_to_agent1'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 115, 'prompt_tokens': 771, 'total_tokens': 886, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'anthropic/claude-sonnet-4', 'system_fingerprint': None, 'id': 'gen-1752340933-4ISCVVJcL5LiivsOuSOx', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--64d5cf0c-0db0-4958-ad95-07cd576c240b-0', tool_calls=[{'name': 'handoff_to_agent1', 'args': {'message': 'Please calculate 68 times 1243435. The temperature in Paris is currently 68¬∞F and I need to multiply it by 1243435.'}, 'id': 'toolu_01YQqA1AGm3eFJi9CMMXWiUJ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 771, 'output_tokens': 115, 'total_tokens': 886, 'input_token_details': {}, 'output_token_details': {}}),\n",
              " ToolMessage(content='Successfully transferred to agent1', id='b0259d4d-3db7-49e4-8f8c-62daf956f3bb', tool_call_id='toolu_01YQqA1AGm3eFJi9CMMXWiUJ'),\n",
              " AIMessage(content=\"Now I'll calculate 68 times 1243435:\", additional_kwargs={'tool_calls': [{'id': 'toolu_01V7AiFqLS7AgC4EA7GHXv1e', 'function': {'arguments': '{\"code\": \"68 * 1243435\"}', 'name': 'execute_python_code'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 75, 'prompt_tokens': 933, 'total_tokens': 1008, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'anthropic/claude-sonnet-4', 'system_fingerprint': None, 'id': 'gen-1752340938-rW5Cv9ZhwefgqJxxP1dZ', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--4b3f3dd2-8ff6-4f2f-8f61-cf05d1176593-0', tool_calls=[{'name': 'execute_python_code', 'args': {'code': '68 * 1243435'}, 'id': 'toolu_01V7AiFqLS7AgC4EA7GHXv1e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 933, 'output_tokens': 75, 'total_tokens': 1008, 'input_token_details': {}, 'output_token_details': {}}),\n",
              " ToolMessage(content='Result: 84553580', name='execute_python_code', id='eb69ca1e-77ad-4a70-93d9-3682dae5809f', tool_call_id='toolu_01V7AiFqLS7AgC4EA7GHXv1e'),\n",
              " AIMessage(content='The current temperature in Paris is 68¬∞F, and when multiplied by 1243435, the result is **84,553,580**.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 1026, 'total_tokens': 1060, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'anthropic/claude-sonnet-4', 'system_fingerprint': None, 'id': 'gen-1752340941-CPc0g5SlsT6Cr2WE8FUK', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--33f80771-a209-4e4e-b636-1886ea247b4a-0', usage_metadata={'input_tokens': 1026, 'output_tokens': 34, 'total_tokens': 1060, 'input_token_details': {}, 'output_token_details': {}})]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "event[list(event.keys())[0]]['messages']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  üì® [HumanMessage]\n",
            "    üí¨ [MESSAGE] Whats is the temperature in Paris times 1243435\n",
            "  üì® [AIMessage]\n",
            "    üõ†Ô∏è [TOOL CALL] üè∑Ô∏è: handoff_to_agent2, üìù: {'message': 'Please get the current temperature in Paris'}, üÜî: toolu_01HS3wFrci9d4EG4nkefS5nL\n",
            "    üí¨ [MESSAGE] I'll help you get the temperature in Paris and then multiply it by 1243435. Let me first get the current temperature in Paris by handing off to Agent 2.\n",
            "  üì® [ToolMessage]\n",
            "    üí¨ [MESSAGE] Successfully transferred to agent2\n",
            "  üì® [AIMessage]\n",
            "    üõ†Ô∏è [TOOL CALL] üè∑Ô∏è: get_weather, üìù: {'city': 'Paris'}, üÜî: toolu_01CetGD8z7VFSAfvREi7YWUy\n",
            "    üí¨ [MESSAGE] Wait, I am Agent 2! Let me get the weather in Paris first:\n",
            "  üì® [ToolMessage]\n",
            "    ‚úÖ [TOOL RESULT] get_weather: The weather in Paris is sunny and 68¬∞F.\n",
            "  üì® [AIMessage]\n",
            "    üõ†Ô∏è [TOOL CALL] üè∑Ô∏è: handoff_to_agent1, üìù: {'message': 'Please calculate 68 times 1243435. The temperature in Paris is currently 68¬∞F and I need to multiply it by 1243435.'}, üÜî: toolu_01YQqA1AGm3eFJi9CMMXWiUJ\n",
            "    üí¨ [MESSAGE] Now I need to multiply 68¬∞F by 1243435. Let me hand this calculation off to Agent 1:\n",
            "  üì® [ToolMessage]\n",
            "    üí¨ [MESSAGE] Successfully transferred to agent1\n",
            "  üì® [AIMessage]\n",
            "    üõ†Ô∏è [TOOL CALL] üè∑Ô∏è: execute_python_code, üìù: {'code': '68 * 1243435'}, üÜî: toolu_01V7AiFqLS7AgC4EA7GHXv1e\n",
            "    üí¨ [MESSAGE] Now I'll calculate 68 times 1243435:\n",
            "  üì® [ToolMessage]\n",
            "    ‚úÖ [TOOL RESULT] execute_python_code: Result: 84553580\n",
            "  üì® [AIMessage]\n",
            "    üí¨ [MESSAGE] The current temperature in Paris is 68¬∞F, and when multiplied by 1243435, the result is **84,553,580**.\n"
          ]
        }
      ],
      "source": [
        "# Print all messages from agent2 in a readable way, using emojis for clarity\n",
        "last_agent_called = list(event.keys())[0]\n",
        "for i, msg in enumerate(event[last_agent_called][\"messages\"]):\n",
        "    print(f\"  üì® [{type(msg).__name__}]\")\n",
        "    # If the message is an AIMessage with tool calls, print tool call details with emojis\n",
        "    if hasattr(msg, \"tool_calls\") and getattr(msg, \"tool_calls\", None):\n",
        "        for tool_call in msg.tool_calls:\n",
        "            print(f\"    üõ†Ô∏è [TOOL CALL] üè∑Ô∏è: {tool_call['name']}, üìù: {tool_call['args']}, üÜî: {tool_call['id']}\")\n",
        "    # If the message is a ToolMessage, print which tool and the result with emojis\n",
        "    if hasattr(msg, \"name\") and hasattr(msg, \"content\") and msg.content:\n",
        "        if getattr(msg, \"name\", None):\n",
        "            print(f\"    ‚úÖ [TOOL RESULT] {msg.name}: {msg.content}\")\n",
        "        else:\n",
        "            print(f\"    üí¨ [MESSAGE] {msg.content}\")\n",
        "    elif msg.content:\n",
        "        print(f\"    üí¨ [MESSAGE] {msg.content}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
