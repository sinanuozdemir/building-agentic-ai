{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c041ad56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… english-words package loaded successfully!\n",
      "ðŸ“š Loaded 9979 valid 5-letter words\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "from typing import List, Literal, Union, NamedTuple, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "import re\n",
    "\n",
    "# English words package for k-letter word support\n",
    "try:\n",
    "    from english_words import get_english_words_set\n",
    "    ENGLISH_WORDS_AVAILABLE = True\n",
    "    print(\"âœ… english-words package loaded successfully!\")\n",
    "except ImportError:\n",
    "    ENGLISH_WORDS_AVAILABLE = False\n",
    "    print(\"âš ï¸  english-words package not found. Install with: pip install english-words\")\n",
    "    print(\"    Falling back to basic word list for 5-letter words only.\")\n",
    "\n",
    "## Wordle-specific data models and utilities for k-letter words\n",
    "\n",
    "class KWordleManager:\n",
    "    \"\"\"Manages k-letter words for flexible Wordle variants\"\"\"\n",
    "    \n",
    "    def __init__(self, word_length: int = 5):\n",
    "        self.word_length = word_length\n",
    "        self._word_cache = {}\n",
    "        self._load_words()\n",
    "    \n",
    "    def _load_words(self):\n",
    "        \"\"\"Load words for the specified length\"\"\"\n",
    "        if ENGLISH_WORDS_AVAILABLE:\n",
    "            try:\n",
    "                # Get comprehensive English word set\n",
    "                all_words = get_english_words_set(['web2'], lower=True)\n",
    "                # Filter for desired length and only alphabetic characters\n",
    "                self.valid_words = {\n",
    "                    word for word in all_words \n",
    "                    if len(word) == self.word_length and word.isalpha()\n",
    "                }\n",
    "                print(f\"ðŸ“š Loaded {len(self.valid_words)} valid {self.word_length}-letter words\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error loading english-words: {e}\")\n",
    "                return []\n",
    "        else:\n",
    "            return []\n",
    "    \n",
    "    def is_valid_word(self, word: str) -> bool:\n",
    "        \"\"\"Check if a word is valid for this k-letter variant\"\"\"\n",
    "        return (len(word) == self.word_length and \n",
    "                word.lower() in self.valid_words and \n",
    "                word.isalpha())\n",
    "    \n",
    "    def get_random_words(self, count: int = 10) -> List[str]:\n",
    "        \"\"\"Get random words for target selection\"\"\"\n",
    "        import random\n",
    "        if not self.valid_words:\n",
    "            return []\n",
    "        return random.sample(list(self.valid_words), min(count, len(self.valid_words)))\n",
    "    \n",
    "    def get_common_starting_words(self, count: int = 5) -> List[str]:\n",
    "        \"\"\"Get good starting words for this length\"\"\"\n",
    "        if self.word_length == 5:\n",
    "            starters = [\"shitfuck\"]\n",
    "            return [w for w in starters if w in self.valid_words][:count]\n",
    "        elif self.word_length == 8:\n",
    "            # Good 8-letter starting words with common letters\n",
    "            potential = [w for w in self.valid_words if \n",
    "                        'e' in w and 'a' in w and ('r' in w or 's' in w or 't' in w)]\n",
    "            import random\n",
    "            return random.sample(potential, min(count, len(potential))) if potential else []\n",
    "        else:\n",
    "            # For other lengths, just pick random words\n",
    "            return self.get_random_words(count)\n",
    "\n",
    "# Global word manager - default to 5 letters (traditional Wordle)\n",
    "WORD_MANAGER = KWordleManager(5)\n",
    "\n",
    "def is_valid_word(word: str, word_length: int = None) -> bool:\n",
    "    \"\"\"Check if a word is valid for k-letter Wordle\"\"\"\n",
    "    if word_length and word_length != WORD_MANAGER.word_length:\n",
    "        # Create temporary manager for different length\n",
    "        temp_manager = KWordleManager(word_length)\n",
    "        return temp_manager.is_valid_word(word)\n",
    "    return WORD_MANAGER.is_valid_word(word)\n",
    "\n",
    "def set_word_length(length: int):\n",
    "    \"\"\"Change the global word length for all Wordle operations\"\"\"\n",
    "    global WORD_MANAGER\n",
    "    WORD_MANAGER = KWordleManager(length)\n",
    "    print(f\"ðŸŽ¯ Switched to {length}-letter Wordle mode!\")\n",
    "    print(f\"   Available words: {len(WORD_MANAGER.valid_words)}\")\n",
    "    print(f\"   Suggested starters: {WORD_MANAGER.get_common_starting_words(3)}\")\n",
    "\n",
    "class WordGuess(BaseModel):\n",
    "    \"\"\"A 5-letter word guess for Wordle.\"\"\"\n",
    "    \n",
    "    word: str = Field(\n",
    "        description=\"A 5-letter word guess\"\n",
    "    )\n",
    "    \n",
    "    def validate_word(self) -> bool:\n",
    "        \"\"\"Validate that this is a proper 5-letter word\"\"\"\n",
    "        return is_valid_word(self.word)\n",
    "\n",
    "class WordleFeedback(BaseModel):\n",
    "    \"\"\"Feedback for a Wordle guess showing colors for each position.\"\"\"\n",
    "    \n",
    "    guess: str = Field(description=\"The guessed word\")\n",
    "    colors: List[str] = Field(\n",
    "        description=\"Color feedback for each letter: 'green', 'yellow', or 'gray'\"\n",
    "    )\n",
    "    \n",
    "    def __str__(self):\n",
    "        colored_letters = []\n",
    "        for letter, color in zip(self.guess, self.colors):\n",
    "            if color == \"green\":\n",
    "                colored_letters.append(f\"{letter}ðŸŸ©\")\n",
    "            elif color == \"yellow\":\n",
    "                colored_letters.append(f\"{letter}ðŸŸ¨\")\n",
    "            else:\n",
    "                colored_letters.append(f\"{letter}â¬œ\")\n",
    "        return \"\".join(colored_letters)\n",
    "\n",
    "class WordleGameState(BaseModel):\n",
    "    \"\"\"Current state of a Wordle game.\"\"\"\n",
    "    \n",
    "    target_word: str = Field(description=\"The target word to guess\")\n",
    "    guesses: List[str] = Field(default=[], description=\"Previous guesses\")\n",
    "    feedback: List[WordleFeedback] = Field(default=[], description=\"Feedback for each guess\")\n",
    "    solved: bool = Field(default=False, description=\"Whether the word has been guessed\")\n",
    "    attempts: int = Field(default=0, description=\"Number of attempts made\")\n",
    "    \n",
    "    def add_guess(self, guess: str) -> WordleFeedback:\n",
    "        \"\"\"Add a guess and return feedback\"\"\"\n",
    "        feedback = simulate_wordle_feedback(guess, self.target_word)\n",
    "        self.guesses.append(guess)\n",
    "        self.feedback.append(feedback)\n",
    "        self.attempts += 1\n",
    "        self.solved = (guess.lower() == self.target_word.lower())\n",
    "        return feedback\n",
    "    \n",
    "    def get_constraints(self) -> dict:\n",
    "        \"\"\"Extract current letter constraints from feedback\"\"\"\n",
    "        green_positions = {}  # position -> letter\n",
    "        yellow_letters = set()  # letters in word but wrong position\n",
    "        gray_letters = set()   # letters not in word\n",
    "        \n",
    "        for feedback in self.feedback:\n",
    "            for i, (letter, color) in enumerate(zip(feedback.guess, feedback.colors)):\n",
    "                if color == \"green\":\n",
    "                    green_positions[i] = letter.lower()\n",
    "                elif color == \"yellow\":\n",
    "                    yellow_letters.add(letter.lower())\n",
    "                else:\n",
    "                    gray_letters.add(letter.lower())\n",
    "        \n",
    "        return {\n",
    "            \"green_positions\": green_positions,\n",
    "            \"yellow_letters\": yellow_letters,\n",
    "            \"gray_letters\": gray_letters\n",
    "        }\n",
    "\n",
    "def simulate_wordle_feedback(guess: str, target: str) -> WordleFeedback:\n",
    "    \"\"\"Simulate Wordle feedback for a guess against a target word of any length.\"\"\"\n",
    "    guess = guess.lower()\n",
    "    target = target.lower()\n",
    "    word_length = len(target)\n",
    "    \n",
    "    # Ensure both words are the same length\n",
    "    if len(guess) != word_length:\n",
    "        # raise ValueError(f\"Guess '{guess}' must be {word_length} letters to match target '{target}'\")\n",
    "        return WordleFeedback(guess=guess, colors=[\"gray\"] * word_length)\n",
    "    \n",
    "    colors = [\"gray\"] * word_length\n",
    "    target_letters = list(target)\n",
    "    \n",
    "    # First pass: mark greens and remove from target\n",
    "    for i in range(word_length):\n",
    "        if guess[i] == target[i]:\n",
    "            colors[i] = \"green\"\n",
    "            target_letters[i] = None  # Mark as used\n",
    "    \n",
    "    # Second pass: mark yellows\n",
    "    for i in range(word_length):\n",
    "        if colors[i] == \"gray\" and guess[i] in target_letters:\n",
    "            colors[i] = \"yellow\"\n",
    "            # Remove first occurrence from target_letters\n",
    "            target_letters[target_letters.index(guess[i])] = None\n",
    "    \n",
    "    return WordleFeedback(guess=guess, colors=colors)\n",
    "\n",
    "class InvalidWordException(Exception):\n",
    "    \"\"\"Raised when user indicates the suggested word is not valid in their Wordle game\"\"\"\n",
    "    def __init__(self, message: str = \"Word not accepted by Wordle\"):\n",
    "        self.message = message\n",
    "        super().__init__(self.message)\n",
    "\n",
    "def get_user_feedback(guess: str, word_length: int) -> WordleFeedback:\n",
    "    \"\"\"Get Wordle feedback from user input for interactive mode.\"\"\"\n",
    "    print(f\"\\nðŸŽ¯ You guessed: '{guess.upper()}'\")\n",
    "    print(\"Please enter the feedback you received from the actual Wordle game.\")\n",
    "    print(f\"Enter {word_length} characters using:\")\n",
    "    print(\"  G or ðŸŸ© = Green (correct letter, correct position)\")\n",
    "    print(\"  Y or ðŸŸ¨ = Yellow (correct letter, wrong position)\")  \n",
    "    print(\"  B or â¬œ = Black/Gray (letter not in word)\")\n",
    "    print(\"Examples: 'GYBGG', 'ðŸŸ©ðŸŸ¨â¬œðŸŸ©ðŸŸ©', 'green yellow black green green'\")\n",
    "    print(\"ðŸ’¡ Or type free text like 'not valid', 'invalid word', 'not accepted' if the word wasn't accepted\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(f\"\\nFeedback for '{guess.upper()}': \").strip()\n",
    "        \n",
    "        # Check for free text responses indicating invalid word\n",
    "        if is_invalid_word_response(user_input):\n",
    "            print(f\"ðŸ“ Got it - '{guess.upper()}' was not accepted by Wordle\")\n",
    "            print(\"ðŸ”„ I'll suggest a different word...\")\n",
    "            raise InvalidWordException(f\"Word '{guess}' not accepted: {user_input}\")\n",
    "        \n",
    "        try:\n",
    "            colors = parse_feedback_input(user_input, word_length)\n",
    "            feedback = WordleFeedback(guess=guess, colors=colors)\n",
    "            print(f\"âœ… Parsed feedback: {feedback}\")\n",
    "            return feedback\n",
    "        except ValueError as e:\n",
    "            print(f\"âŒ Error: {e}\")\n",
    "            print(\"Please try again with the correct format, or type 'not valid' if the word wasn't accepted.\")\n",
    "\n",
    "def is_invalid_word_response(user_input: str) -> bool:\n",
    "    \"\"\"Check if user input indicates the word was not valid/accepted.\"\"\"\n",
    "    input_lower = user_input.lower().strip()\n",
    "    \n",
    "    # Common phrases indicating invalid word\n",
    "    invalid_phrases = [\n",
    "        \"not valid\", \"invalid\", \"not accepted\", \"rejected\", \"not allowed\",\n",
    "        \"not in list\", \"unknown word\", \"not recognized\", \"doesn't work\",\n",
    "        \"can't use\", \"won't accept\", \"error\", \"failed\", \"bad word\",\n",
    "        \"not a word\", \"no good\", \"skip\", \"try again\", \"different word\", \"notinwordlist\", \"NOTINWORDLIST\"\n",
    "    ]\n",
    "    \n",
    "    # Check if any invalid phrase is contained in the response\n",
    "    for phrase in invalid_phrases:\n",
    "        if phrase in input_lower:\n",
    "            return True\n",
    "    \n",
    "    # Also check for very short responses that are likely complaints\n",
    "    if len(input_lower) < 8 and any(word in input_lower for word in [\"no\", \"nope\", \"bad\", \"wrong\", \"fail\"]):\n",
    "        return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "def parse_feedback_input(user_input: str, expected_length: int) -> List[str]:\n",
    "    \"\"\"Parse various user input formats into color list.\"\"\"\n",
    "    user_input = user_input.upper().replace(\" \", \"\")\n",
    "    \n",
    "    # Handle emoji input\n",
    "    if \"ðŸŸ©\" in user_input or \"ðŸŸ¨\" in user_input or \"â¬œ\" in user_input:\n",
    "        colors = []\n",
    "        for char in user_input:\n",
    "            if char == \"ðŸŸ©\":\n",
    "                colors.append(\"green\")\n",
    "            elif char == \"ðŸŸ¨\":\n",
    "                colors.append(\"yellow\")\n",
    "            elif char == \"â¬œ\":\n",
    "                colors.append(\"gray\")\n",
    "        if len(colors) == expected_length:\n",
    "            return colors\n",
    "    \n",
    "    # Handle G/Y/B format\n",
    "    if len(user_input) == expected_length and all(c in \"GYB\" for c in user_input):\n",
    "        color_map = {\"G\": \"green\", \"Y\": \"yellow\", \"B\": \"gray\"}\n",
    "        return [color_map[c] for c in user_input]\n",
    "    \n",
    "    # Handle full word format\n",
    "    words = user_input.replace(\",\", \" \").split()\n",
    "    if len(words) == expected_length:\n",
    "        colors = []\n",
    "        for word in words:\n",
    "            if word.startswith(\"G\"):\n",
    "                colors.append(\"green\")\n",
    "            elif word.startswith(\"Y\"):\n",
    "                colors.append(\"yellow\") \n",
    "            elif word.startswith(\"B\") or word.startswith(\"GR\"):\n",
    "                colors.append(\"gray\")\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown color: {word}\")\n",
    "        return colors\n",
    "    \n",
    "    raise ValueError(f\"Input must be exactly {expected_length} colors. Got: '{user_input}'\")\n",
    "\n",
    "## These objects will represent a single \"candidate\" (or scored candidate) within our agent's state.\n",
    "\n",
    "class WordCandidate(NamedTuple):\n",
    "    word: str\n",
    "    reasoning: Optional[str] = None\n",
    "    score: Optional[float] = None\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"WordGuess('{self.word}') - {self.reasoning} (Score: {self.score})\"\n",
    "\n",
    "class ScoredWordCandidate(NamedTuple):\n",
    "    word: str\n",
    "    reasoning: Optional[str] = None\n",
    "    score: float = 0.0\n",
    "    llm_reasoning: str = \"\"\n",
    "    bucket: str = \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c947ec0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ® K-Letter Wordle System Initialized!\n",
      "Current mode: 5-letter words\n",
      "Available words: 9979\n",
      "ðŸ“– Example words for different lengths:\n",
      "ðŸ“š Loaded 9979 valid 5-letter words\n",
      "  5-letter: ['ramon', 'durio', 'aught'] (suggested starters: [])\n",
      "ðŸ“š Loaded 17468 valid 6-letter words\n",
      "  6-letter: ['dunker', 'opaled', 'jibman'] (suggested starters: ['solely', 'sachet'])\n",
      "ðŸ“š Loaded 23723 valid 7-letter words\n",
      "  7-letter: ['pageant', 'spinose', 'deborah'] (suggested starters: ['lycopod', 'mowable'])\n",
      "ðŸ“š Loaded 29851 valid 8-letter words\n",
      "  8-letter: ['killcrop', 'wingfish', 'cocksure'] (suggested starters: ['taenidia', 'riddance'])\n",
      "\n",
      "ðŸŽ¯ Current target words: ['isawa', 'dixit', 'roger', 'shiko', 'drawn']\n"
     ]
    }
   ],
   "source": [
    "# Initialize default word manager and demonstrate k-letter functionality\n",
    "print(\"ðŸŽ® K-Letter Wordle System Initialized!\")\n",
    "print(f\"Current mode: {WORD_MANAGER.word_length}-letter words\")\n",
    "print(f\"Available words: {len(WORD_MANAGER.valid_words)}\")\n",
    "\n",
    "# Function to get target words for the current word length\n",
    "def get_target_words(count: int = 10) -> List[str]:\n",
    "    \"\"\"Get random target words for the current word length\"\"\"\n",
    "    return WORD_MANAGER.get_random_words(count)\n",
    "\n",
    "def get_target_word(index: int = 0) -> str:\n",
    "    \"\"\"Get a specific target word for Wordle game\"\"\"\n",
    "    words = get_target_words(50)  # Get a good selection\n",
    "    return words[index % len(words)] if words else \"crane\"\n",
    "\n",
    "# Demo: Show words for different lengths\n",
    "print(\"ðŸ“– Example words for different lengths:\")\n",
    "for length in [5, 6, 7, 8]:\n",
    "    try:\n",
    "        temp_manager = KWordleManager(length)\n",
    "        if temp_manager.valid_words:\n",
    "            sample_words = temp_manager.get_random_words(3)\n",
    "            starters = temp_manager.get_common_starting_words(2)\n",
    "            print(f\"  {length}-letter: {sample_words} (suggested starters: {starters})\")\n",
    "        else:\n",
    "            print(f\"  {length}-letter: No words available\")\n",
    "    except Exception as e:\n",
    "        print(f\"  {length}-letter: Error - {e}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Current target words: {get_target_words(5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4df5b715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Switching to 5-letter Wordle mode...\n",
      "ðŸ“š Loaded 9979 valid 5-letter words\n",
      "ðŸŽ¯ Switched to 5-letter Wordle mode!\n",
      "   Available words: 9979\n",
      "   Suggested starters: []\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ”„ Switching to 5-letter Wordle mode...\")\n",
    "set_word_length(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "882557be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class GuessWords(BaseModel):\n",
    "    \"\"\"Submit multiple word guesses for k-letter Wordle.\"\"\"\n",
    "\n",
    "    reasoning: str = Field(\n",
    "        description=\"The reasoning behind the submitted word guesses. Explain your strategy for each word.\"\n",
    "    )\n",
    "\n",
    "    words: List[WordGuess] = Field(\n",
    "        description=\"The list of words to submit as guesses. Each word must match the current game's word length.\"\n",
    "    )\n",
    "\n",
    "class WordleScoring(BaseModel):\n",
    "    \"\"\"LLM evaluation of a Wordle guess\"\"\"\n",
    "    \n",
    "    reasoning: str = Field(\n",
    "        description=\"Detailed reasoning for why this word is good/bad given the game state\"\n",
    "    )\n",
    "    \n",
    "    score: int = Field(\n",
    "        description=\"Score from 1-100 for how good this guess is\",\n",
    "        ge=1, le=100\n",
    "    )\n",
    "    \n",
    "    strategic_value: str = Field(\n",
    "        description=\"Brief explanation of the strategic value of this guess\"\n",
    "    )\n",
    "\n",
    "# Word generation prompt (supports k-letter words)\n",
    "generation_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are an expert {word_length}-letter Wordle player. Generate strategic {word_length}-letter word guesses.\\n\"\n",
    "     \"Consider: letter frequency, position strategy, information gain, and elimination potential.\\n\"\n",
    "     \"Submit exactly {k} word guesses for this round.\\n\"\n",
    "     \"Only suggest valid {word_length}-letter English words.\"),\n",
    "    (\"user\", \n",
    "     \"Game state:\\n\"\n",
    "     \"Previous guesses and feedback: {game_history}\\n\"\n",
    "     \"Current constraints: {constraints}\\n\"\n",
    "     \"Attempts made: {attempts}/6\\n\\n\"\n",
    "     \"Suggest your next {word_length}-letter word guesses.{candidate}\")\n",
    "])\n",
    "\n",
    "# Scoring prompt (supports k-letter words)\n",
    "scoring_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     \"You are an expert {word_length}-letter Wordle player. Rate the quality of {word_length}-letter word guesses on a scale of 1-100.\\n\"\n",
    "     \"Consider: letter frequency, position strategy, information gain, and elimination potential.\\n\"\n",
    "     \"Higher scores for words that help narrow down possibilities efficiently.\\n\"\n",
    "     \"Lower scores for words that waste information or repeat known facts.\"),\n",
    "    (\"user\", \n",
    "     \"Game State:\\n\"\n",
    "     \"Previous guesses and feedback: {game_history}\\n\"\n",
    "     \"Current constraints: {constraints}\\n\"\n",
    "     \"Attempts made: {attempts}/6\\n\\n\"\n",
    "     \"Rate this {word_length}-letter guess: '{word}'\\n\"\n",
    "     \"Explain your reasoning and give a score 1-100.\")\n",
    "])\n",
    "\n",
    "def bucket_score(score: int) -> str:\n",
    "    \"\"\"Convert 1-100 score to bucket categories\"\"\"\n",
    "    if score >= 80:\n",
    "        return \"excellent\"\n",
    "    elif score >= 60:\n",
    "        return \"good\" \n",
    "    elif score >= 40:\n",
    "        return \"ok\"\n",
    "    elif score >= 20:\n",
    "        return \"poor\"\n",
    "    else:\n",
    "        return \"bad\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cab46ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_game_history(game_state: WordleGameState) -> str:\n",
    "    \"\"\"Format the game history for LLM consumption\"\"\"\n",
    "    if not game_state.guesses:\n",
    "        return \"No previous guesses.\"\n",
    "    \n",
    "    history = []\n",
    "    for guess, feedback in zip(game_state.guesses, game_state.feedback):\n",
    "        history.append(f\"Guess: {guess.upper()} â†’ {feedback}\")\n",
    "    \n",
    "    return \"\\n\".join(history)\n",
    "\n",
    "def format_constraints(game_state: WordleGameState) -> str:\n",
    "    \"\"\"Format current constraints for LLM consumption\"\"\"\n",
    "    constraints = game_state.get_constraints()\n",
    "    \n",
    "    parts = []\n",
    "    if constraints[\"green_positions\"]:\n",
    "        green_info = [f\"Position {i+1}: {letter.upper()}\" \n",
    "                     for i, letter in constraints[\"green_positions\"].items()]\n",
    "        parts.append(f\"Known letters (green): {', '.join(green_info)}\")\n",
    "    \n",
    "    if constraints[\"yellow_letters\"]:\n",
    "        parts.append(f\"Letters in word but wrong position (yellow): {', '.join(letter.upper() for letter in constraints['yellow_letters'])}\")\n",
    "    \n",
    "    if constraints[\"gray_letters\"]:\n",
    "        parts.append(f\"Letters NOT in word (gray): {', '.join(letter.upper() for letter in constraints['gray_letters'])}\")\n",
    "    \n",
    "    return \"; \".join(parts) if parts else \"No constraints yet.\"\n",
    "\n",
    "def compute_score(game_state: WordleGameState, candidate: WordCandidate) -> ScoredWordCandidate:\n",
    "    \"\"\"Use LLM to score how good a word guess is given current game state\"\"\"\n",
    "\n",
    "    # Check if word was already guessed\n",
    "    if candidate.word.lower() in [guess.lower() for guess in game_state.guesses]:\n",
    "        return ScoredWordCandidate(\n",
    "            word=candidate.word,\n",
    "            score=0.0,\n",
    "            llm_reasoning=\"Invalid: word already guessed\",\n",
    "            bucket=\"bad\"\n",
    "        )\n",
    "    \n",
    "    # Prepare context for the LLM\n",
    "    game_history = format_game_history(game_state)\n",
    "    constraints = format_constraints(game_state)\n",
    "    \n",
    "    try:\n",
    "        scoring_result = word_scorer.invoke({\n",
    "            \"game_history\": game_history,\n",
    "            \"constraints\": constraints,\n",
    "            \"attempts\": game_state.attempts,\n",
    "            \"word\": candidate.word,\n",
    "            \"word_length\": WORD_MANAGER.word_length\n",
    "        },\n",
    "        model_kwargs={\"include_reasoning\": True, \"reasoning_effort\": \"medium\"}\n",
    "        )\n",
    "        \n",
    "        # Convert 1-100 score to 0-1 for consistency with existing framework\n",
    "        normalized_score = scoring_result.score / 100.0\n",
    "        bucket = bucket_score(scoring_result.score)\n",
    "        \n",
    "        return ScoredWordCandidate(\n",
    "            word=candidate.word,\n",
    "            reasoning=candidate.reasoning,\n",
    "            score=normalized_score,\n",
    "            llm_reasoning=scoring_result.reasoning,\n",
    "            bucket=bucket\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fda5fcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wordle Tree of Thought graph compiled successfully!\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "from typing import Optional, Dict, Any, Union, List, Literal\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.runtime import Runtime\n",
    "\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.types import Send\n",
    "\n",
    "\n",
    "def update_candidates(\n",
    "    existing: Optional[list] = None,\n",
    "    updates: Optional[Union[list, Literal[\"clear\"]]] = None,\n",
    ") -> List[str]:\n",
    "    if existing is None:\n",
    "        existing = []\n",
    "    if updates is None:\n",
    "        return existing\n",
    "    if updates == \"clear\":\n",
    "        return []\n",
    "    # Concatenate the lists\n",
    "    # return existing + updates\n",
    "    return updates\n",
    "\n",
    "\n",
    "class WordleToTState(TypedDict):\n",
    "    game_state: WordleGameState\n",
    "    candidates: Annotated[List[WordCandidate], update_candidates]\n",
    "    scored_candidates: Annotated[List[ScoredWordCandidate], update_candidates]\n",
    "    depth: Annotated[int, operator.add]\n",
    "    # Context parameters added directly to state\n",
    "    max_depth: int\n",
    "    threshold: float  # High threshold for accepting solutions (default 0.75)\n",
    "    high_threshold: float  # Threshold for keeping candidates normally (default 0.6)\n",
    "    retry_threshold: float  # Minimum threshold for retry generation (default 0.4)\n",
    "    k: int\n",
    "    beam_size: int\n",
    "    # Performance tracking counters\n",
    "    generation_count: Annotated[int, operator.add]  # Number of word generation calls\n",
    "    scoring_count: Annotated[int, operator.add]     # Number of word scoring calls\n",
    "\n",
    "class WordleExpansionState(WordleToTState):\n",
    "    seed: Optional[WordCandidate]\n",
    "\n",
    "\n",
    "def expand(state: WordleExpansionState) -> Dict[str, List[WordCandidate]]:\n",
    "    \"\"\"Generate the next candidate word guesses.\"\"\"\n",
    "    print(f'Expanding with seed: {state.get(\"seed\")}')\n",
    "    \n",
    "    # Prepare context for word generation\n",
    "    game_state = state[\"game_state\"]\n",
    "    game_history = format_game_history(game_state)\n",
    "    print(\"GAME HISTORY: \", game_history)\n",
    "    constraints = format_constraints(game_state)\n",
    "    \n",
    "    if not state.get(\"seed\"):\n",
    "        candidate_str = \"\"\n",
    "    else:\n",
    "        seed = state[\"seed\"]\n",
    "        if hasattr(seed, 'llm_reasoning') and seed.llm_reasoning:\n",
    "            candidate_str = (f\"\\n\\nI previously considered '{seed.word.upper()}' with this reasoning: \"\n",
    "                           f\"{seed.llm_reasoning} \"\n",
    "                           f\"But I need a better guess. Please suggest alternatives that address \"\n",
    "                           f\"the limitations of this previous attempt.\")\n",
    "        else:\n",
    "            candidate_str = (f\"\\n\\nI previously considered '{seed.word.upper()}' but it wasn't scored \"\n",
    "                           f\"highly enough. Please suggest better alternatives.\")\n",
    "    \n",
    "    try:\n",
    "        print(f'Generating {state[\"k\"]} word candidates for game with {game_state.attempts} attempts')\n",
    "        print(f'Word length: {WORD_MANAGER.word_length}')\n",
    "        word_submission = word_generator.invoke({\n",
    "            \"game_history\": game_history,\n",
    "            \"constraints\": constraints,\n",
    "            \"attempts\": game_state.attempts,\n",
    "            \"candidate\": candidate_str,\n",
    "            \"k\": state[\"k\"],\n",
    "            \"word_length\": WORD_MANAGER.word_length\n",
    "        },\n",
    "        model_kwargs={\"include_reasoning\": True, \"reasoning_effort\": \"medium\"}\n",
    "        )\n",
    "        \n",
    "        new_candidates = [\n",
    "            WordCandidate(word=word_guess.word, reasoning=word_submission.reasoning) \n",
    "            for word_guess in word_submission.words\n",
    "        ]\n",
    "        \n",
    "        print(f'Generated candidates: {[c.word for c in new_candidates]}')\n",
    "        return {\"candidates\": new_candidates, \"generation_count\": 1}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'Error in expansion: {e}')\n",
    "        raise ValueError(f'Error in expansion: {e}')\n",
    "\n",
    "\n",
    "def score(state: WordleToTState) -> Dict[str, Any]:\n",
    "    \"\"\"Evaluate the candidate word generations using LLM scoring.\"\"\"\n",
    "    candidates = state[\"candidates\"]\n",
    "    game_state = state[\"game_state\"]\n",
    "    scored = []\n",
    "    \n",
    "    print(f'Scoring {len(candidates)} candidates')\n",
    "    for candidate in candidates:\n",
    "        scored_candidate = compute_score(game_state, candidate)\n",
    "        scored.append(scored_candidate)\n",
    "        print(f'LLM Reasoning: {scored_candidate.llm_reasoning}')\n",
    "        print(f'  {candidate.word}: {scored_candidate.score:.2f} ({scored_candidate.bucket})')\n",
    "    \n",
    "    # Count the number of scoring operations\n",
    "    scoring_operations = len(candidates)\n",
    "    print(f'ðŸ“Š Performed {scoring_operations} scoring operations')\n",
    "    \n",
    "    return {\"scored_candidates\": scored, \"candidates\": \"clear\", \"scoring_count\": scoring_operations}\n",
    "\n",
    "\n",
    "def prune(state: WordleToTState) -> Dict[str, Any]:\n",
    "    \"\"\"Adaptive pruning: Keep best candidates or trigger retry for mediocre ones.\"\"\"\n",
    "    scored_candidates = state[\"scored_candidates\"]\n",
    "    beam_size = state[\"beam_size\"]\n",
    "    high_threshold = state[\"high_threshold\"]\n",
    "    retry_threshold = state[\"retry_threshold\"]\n",
    "    \n",
    "    organized = sorted(\n",
    "        scored_candidates, key=lambda candidate: candidate.score, reverse=True\n",
    "    )\n",
    "    \n",
    "    # Check if any candidates meet the high threshold\n",
    "    high_quality = [c for c in organized if c.score >= high_threshold]\n",
    "    \n",
    "    if high_quality:\n",
    "        # Normal pruning: keep the best candidates\n",
    "        pruned = high_quality[:beam_size]\n",
    "        print(f'âœ… Normal pruning: {len(pruned)} high-quality candidates above {high_threshold:.2f}')\n",
    "        print(f'   Selected: {[(c.word, f\"{c.score:.2f}\") for c in pruned]}')\n",
    "        \n",
    "        return {\n",
    "            \"candidates\": pruned,\n",
    "            \"scored_candidates\": \"clear\",\n",
    "            \"depth\": 1,\n",
    "        }\n",
    "    else:\n",
    "        # Adaptive retry: find candidates worth retrying with more thought\n",
    "        retry_worthy = [c for c in organized if c.score >= retry_threshold]\n",
    "        \n",
    "        if retry_worthy:\n",
    "            print(f'ðŸ”„ Adaptive retry: No candidates above {high_threshold:.2f}, retrying with {len(retry_worthy)} candidates above {retry_threshold:.2f}')\n",
    "            print(f'   Retry candidates: {[(c.word, f\"{c.score:.2f}\") for c in retry_worthy]}')\n",
    "            \n",
    "            # Clear all current candidates and use retry-worthy ones as seeds\n",
    "            return {\n",
    "                \"candidates\": retry_worthy[:beam_size],  # Limit to beam_size for retry\n",
    "                \"scored_candidates\": \"clear\",\n",
    "                \"depth\": 1,\n",
    "            }\n",
    "        else:\n",
    "            # Fallback: keep best candidates even if they're below thresholds\n",
    "            pruned = organized[:beam_size]\n",
    "            print(f'âš ï¸  Fallback pruning: All candidates below {retry_threshold:.2f}, keeping best {len(pruned)}')\n",
    "            print(f'   Fallback: {[(c.word, f\"{c.score:.2f}\") for c in pruned]}')\n",
    "            \n",
    "            return {\n",
    "                \"candidates\": pruned,\n",
    "                \"scored_candidates\": \"clear\",\n",
    "                \"depth\": 1,\n",
    "            }\n",
    "\n",
    "\n",
    "def should_terminate(state: WordleToTState) -> Union[Literal[\"__end__\"], Send]:\n",
    "    \"\"\"Decide whether to continue expanding or terminate.\"\"\"\n",
    "    if not state[\"candidates\"]:\n",
    "        print(\"Terminating: No candidates available\")\n",
    "        return \"__end__\"\n",
    "    \n",
    "    # Check if we have a high-quality solution\n",
    "    best_candidate = state[\"candidates\"][0]\n",
    "    solved = hasattr(best_candidate, 'score') and best_candidate.score >= state[\"threshold\"]\n",
    "    \n",
    "    if solved:\n",
    "        print(f\"Terminating: Found high-quality solution: {best_candidate.word} (score: {best_candidate.score:.2f})\")\n",
    "        return \"__end__\"\n",
    "    \n",
    "    if state[\"depth\"] >= state[\"max_depth\"]:\n",
    "        print(f\"Terminating: Reached max depth {state['max_depth']}\")\n",
    "        return \"__end__\"\n",
    "    \n",
    "    print(f\"Continuing to depth {state['depth'] + 1} with {len(state['candidates'])} candidates\")\n",
    "    return [\n",
    "        Send(\"expand\", {**state, \"seed\": candidate})\n",
    "        for candidate in state[\"candidates\"]\n",
    "    ]\n",
    "\n",
    "\n",
    "# Create the graph\n",
    "builder = StateGraph(state_schema=WordleToTState)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node(expand)\n",
    "builder.add_node(score)\n",
    "builder.add_node(prune)\n",
    "\n",
    "# Add edges\n",
    "builder.add_edge(\"expand\", \"score\")\n",
    "builder.add_edge(\"score\", \"prune\")\n",
    "builder.add_conditional_edges(\"prune\", should_terminate, path_map=[\"expand\", \"__end__\"])\n",
    "\n",
    "# Set entry point\n",
    "builder.add_edge(\"__start__\", \"expand\")\n",
    "\n",
    "# Compile the graph\n",
    "tot_graph = builder.compile(checkpointer=InMemorySaver())\n",
    "\n",
    "print(\"Wordle Tree of Thought graph compiled successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "294c7fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Visualize the Tree of Thought workflow graph\n",
    "display(Image(tot_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53be69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_wordle_with_tot(target_word: str = None, max_attempts: int = 6, \n",
    "                        tot_params: dict = None, interactive: bool = False) -> dict:\n",
    "    \"\"\"Play a complete game of Wordle using Tree of Thought for word selection\n",
    "    \n",
    "    Args:\n",
    "        target_word: The target word (None for interactive mode)\n",
    "        max_attempts: Maximum number of attempts\n",
    "        tot_params: Tree of Thought parameters\n",
    "        interactive: If True, ask user for feedback instead of simulating\n",
    "    \n",
    "    Returns:\n",
    "        dict: Game result with statistics including generation and scoring counts\n",
    "    \"\"\"\n",
    "    \n",
    "    if tot_params is None:\n",
    "        tot_params = {\n",
    "            \"max_depth\": 2,          # How deep to search for word candidates\n",
    "            \"threshold\": 0.80,       # Stop if we find a word with 95+ score (solution threshold)\n",
    "            \"high_threshold\": 0.60,  # Threshold for normal pruning (keep good candidates)\n",
    "            \"retry_threshold\": 0.40, # Minimum threshold for retry generation\n",
    "            \"k\": 4,                  # Generate 4 word candidates per round\n",
    "            \"beam_size\": 3           # Keep top 3 candidates for next iteration\n",
    "        }\n",
    "    \n",
    "    # Handle interactive mode setup\n",
    "    if interactive:\n",
    "        if target_word is None:\n",
    "            target_word = \"UNKNOWN\"  # Placeholder for interactive mode\n",
    "        print(f\"ðŸŽ® Starting INTERACTIVE Wordle session!\")\n",
    "        print(f\"ðŸ’¡ I'll suggest words using Tree of Thought, you provide the feedback!\")\n",
    "        print(f\"ðŸŽ¯ Word length: {WORD_MANAGER.word_length} letters\")\n",
    "    else:\n",
    "        if target_word is None:\n",
    "            target_word = get_target_word(0)  # Get random target word\n",
    "        print(f\"ðŸŽ¯ Starting Wordle game with target word: '{target_word.upper()}'\")\n",
    "    \n",
    "    # Initialize game state and performance counters\n",
    "    game_state = WordleGameState(target_word=target_word)\n",
    "    total_generations = 0\n",
    "    total_scorings = 0\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    attempt = 1\n",
    "    while not game_state.solved and attempt <= max_attempts:\n",
    "        print(f\"\\nðŸ“ Attempt {attempt}/{max_attempts}\")\n",
    "        print(f\"Previous guesses: {', '.join(game_state.guesses)}\")\n",
    "        \n",
    "        # Use Tree of Thought to find the best next word\n",
    "        print(\"\\nðŸ§  Using Tree of Thought to find next word...\")\n",
    "        \n",
    "        tot_result = tot_graph.stream(\n",
    "            {\n",
    "                \"game_state\": game_state,\n",
    "                \"candidates\": [],\n",
    "                \"scored_candidates\": [],\n",
    "                \"depth\": 0,\n",
    "                \"generation_count\": 0,  # Initialize generation counter\n",
    "                \"scoring_count\": 0,     # Initialize scoring counter\n",
    "                **tot_params\n",
    "            },\n",
    "            config={\"configurable\": {\"thread_id\": f\"wordle_game_{attempt}\"}},\n",
    "        )\n",
    "        \n",
    "        # Extract the final best word from ToT and accumulate performance counts\n",
    "        final_state = None\n",
    "        attempt_generations = 0\n",
    "        attempt_scorings = 0\n",
    "        \n",
    "        for step in tot_result:\n",
    "            # Track generation and scoring counts from each step\n",
    "            for node, state in step.items():\n",
    "                if isinstance(state, dict):\n",
    "                    if 'generation_count' in state:\n",
    "                        attempt_generations += state['generation_count']\n",
    "                    if 'scoring_count' in state:\n",
    "                        attempt_scorings += state['scoring_count']\n",
    "            \n",
    "            # Keep the final prune state for word selection\n",
    "            if step.get('prune'):\n",
    "                final_state = step['prune']\n",
    "        \n",
    "        # Accumulate totals\n",
    "        total_generations += attempt_generations\n",
    "        total_scorings += attempt_scorings\n",
    "        print(f\"ðŸ“Š Attempt {attempt} ToT stats: {attempt_generations} generations, {attempt_scorings} scorings\")\n",
    "        \n",
    "        if not final_state or not final_state.get('candidates'):\n",
    "            print(\"âŒ ToT failed to generate candidates\")\n",
    "            if interactive:\n",
    "                print(\"ðŸ”„ Will retry generation in next iteration...\")\n",
    "                continue  # Skip this iteration and try again\n",
    "            else:\n",
    "                # Fallback to a common starting word for simulated mode\n",
    "                fallback_words = WORD_MANAGER.get_common_starting_words(1)\n",
    "                next_word = fallback_words[0] if fallback_words else \"crane\"\n",
    "                print(f\"ðŸŽ¯ Using fallback word: '{next_word.upper()}'\")\n",
    "        else:\n",
    "            best_candidate = final_state['candidates'][0]\n",
    "            next_word = best_candidate.word\n",
    "            print(f\"ðŸŽ¯ ToT selected: '{next_word.upper()}' (score: {best_candidate.score:.2f})\")\n",
    "            if hasattr(best_candidate, 'llm_reasoning'):\n",
    "                print(f\"ðŸ’­ Reasoning: {best_candidate.llm_reasoning[:100]}...\")\n",
    "        \n",
    "        # Get feedback (interactive vs simulated)\n",
    "        if interactive:\n",
    "            # Interactive mode: ask user for real Wordle feedback\n",
    "            try:\n",
    "                feedback = get_user_feedback(next_word, WORD_MANAGER.word_length)\n",
    "                \n",
    "                # Manually add to game state (bypassing automatic simulation)\n",
    "                game_state.guesses.append(next_word)\n",
    "                game_state.feedback.append(feedback)\n",
    "                game_state.attempts += 1\n",
    "                \n",
    "                # Check if solved (all green)\n",
    "                if all(color == \"green\" for color in feedback.colors):\n",
    "                    game_state.solved = True\n",
    "                    print(f\"\\nðŸŽ‰ SUCCESS! Solved in {attempt} attempts!\")\n",
    "                    break\n",
    "                    \n",
    "            except InvalidWordException as e:\n",
    "                print(f\"âš ï¸ Word not accepted: {e.message}\")\n",
    "                \n",
    "                # Try to get an alternative word from remaining candidates\n",
    "                if final_state and len(final_state.get('candidates', [])) > 1:\n",
    "                    # Use the next best candidate\n",
    "                    alt_candidate = final_state['candidates'][1]\n",
    "                    print(f\"ðŸŽ¯ Trying alternative: '{alt_candidate.word.upper()}' (score: {alt_candidate.score:.2f})\")\n",
    "                    next_word = alt_candidate.word\n",
    "                    \n",
    "                    # Remove the failed word from candidates and try again\n",
    "                    final_state['candidates'] = final_state['candidates'][1:]\n",
    "                    continue  # Retry with alternative word (don't increment attempt)\n",
    "                else:\n",
    "                    print(\"âŒ No alternative words available. Generating new candidates...\")\n",
    "                    # Continue to next iteration to regenerate words\n",
    "                    continue\n",
    "                \n",
    "        else:\n",
    "            # Simulated mode: automatic feedback generation\n",
    "            feedback = game_state.add_guess(next_word)\n",
    "            print(f\"ðŸ“Š Feedback: {feedback}\")\n",
    "            \n",
    "            if game_state.solved:\n",
    "                print(f\"\\nðŸŽ‰ SUCCESS! Solved in {attempt} attempts!\")\n",
    "                break\n",
    "        \n",
    "        attempt += 1\n",
    "    \n",
    "    if not game_state.solved:\n",
    "        if interactive:\n",
    "            print(f\"\\nâ° Reached maximum attempts ({max_attempts})\")\n",
    "            print(f\"ðŸ’¡ Feel free to continue manually or start a new session!\")\n",
    "        else:\n",
    "            print(f\"\\nðŸ˜ž Failed to solve. The word was: '{target_word.upper()}'\")\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Final game statistics:\")\n",
    "    if interactive:\n",
    "        print(f\"  Mode: Interactive ({WORD_MANAGER.word_length}-letter)\")\n",
    "        print(f\"  Target: [Hidden - you know it! ðŸ˜‰]\")\n",
    "    else:\n",
    "        print(f\"  Target: {target_word.upper()}\")\n",
    "    print(f\"  Attempts: {game_state.attempts}/{max_attempts}\")\n",
    "    print(f\"  Success: {'Yes' if game_state.solved else 'No'}\")\n",
    "    print(f\"  Guesses: {' â†’ '.join(guess.upper() for guess in game_state.guesses)}\")\n",
    "    print(f\"  ToT Performance:\")\n",
    "    print(f\"    Total generations: {total_generations}\")\n",
    "    print(f\"    Total scorings: {total_scorings}\")\n",
    "    if game_state.attempts > 0:\n",
    "        print(f\"    Avg generations per attempt: {total_generations/game_state.attempts:.1f}\")\n",
    "        print(f\"    Avg scorings per attempt: {total_scorings/game_state.attempts:.1f}\")\n",
    "    \n",
    "    # Return comprehensive result\n",
    "    return {\n",
    "        'game_state': game_state,\n",
    "        'target_word': target_word if not interactive else \"HIDDEN\",\n",
    "        'solved': game_state.solved,\n",
    "        'attempts': game_state.attempts,\n",
    "        'max_attempts': max_attempts,\n",
    "        'guesses': game_state.guesses,\n",
    "        'interactive_mode': interactive,\n",
    "        'word_length': WORD_MANAGER.word_length,\n",
    "        'success_rate': 1.0 if game_state.solved else 0.0,\n",
    "        'efficiency_score': (max_attempts - game_state.attempts + 1) / max_attempts if game_state.solved else 0.0,\n",
    "        'tot_performance': {\n",
    "            'total_generations': total_generations,\n",
    "            'total_scorings': total_scorings,\n",
    "            'avg_generations_per_attempt': total_generations / game_state.attempts if game_state.attempts > 0 else 0,\n",
    "            'avg_scorings_per_attempt': total_scorings / game_state.attempts if game_state.attempts > 0 else 0,\n",
    "            'total_llm_calls': total_generations + total_scorings\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Test the system with a sample word\n",
    "test_word = get_target_word(0)  # Get first target word\n",
    "\n",
    "# LLM setup\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-nano\")\n",
    "scoring_llm = ChatOpenAI(model=\"gpt-4.1-nano\")\n",
    "\n",
    "# Bound LLMs for each task\n",
    "word_generator = generation_prompt | llm.with_structured_output(GuessWords)\n",
    "word_scorer = scoring_prompt | llm.with_structured_output(WordleScoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d106bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Testing Enhanced Performance Tracking\n",
      "==================================================\n",
      "Playing with 5-letter word: 'AHURA'\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“Š DEMO: Enhanced Performance Tracking with Generation & Scoring Counters\n",
    "print(\"ðŸŽ¯ Testing Enhanced Performance Tracking\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test with current word length\n",
    "current_word = get_target_word(0)\n",
    "print(f\"Playing with {WORD_MANAGER.word_length}-letter word: '{current_word.upper()}'\")\n",
    "\n",
    "\n",
    "\n",
    "def analyze_tot_performance(result: dict):\n",
    "    \"\"\"Detailed analysis of ToT performance metrics\"\"\"\n",
    "    print(f\"\\nðŸ” Detailed ToT Performance Analysis\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    perf = result['tot_performance']\n",
    "    game_state = result['game_state']\n",
    "    \n",
    "    print(f\"ðŸŽ¯ Game Outcome:\")\n",
    "    print(f\"  Target: {result['target_word'].upper()}\")\n",
    "    print(f\"  Result: {'âœ… SOLVED' if result['solved'] else 'âŒ FAILED'}\")\n",
    "    print(f\"  Attempts: {result['attempts']}/{result['max_attempts']}\")\n",
    "    print(f\"  Efficiency: {result['efficiency_score']:.1%}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š ToT Algorithm Performance:\")\n",
    "    print(f\"  Total LLM Calls: {perf['total_llm_calls']}\")\n",
    "    print(f\"    â€¢ Word Generation Calls: {perf['total_generations']}\")\n",
    "    print(f\"    â€¢ Word Scoring Calls: {perf['total_scorings']}\")\n",
    "    print(f\"  Per-Attempt Averages:\")\n",
    "    print(f\"    â€¢ {perf['avg_generations_per_attempt']:.1f} generations per attempt\")\n",
    "    print(f\"    â€¢ {perf['avg_scorings_per_attempt']:.1f} scorings per attempt\")\n",
    "    print(f\"    â€¢ {perf['total_llm_calls']/result['attempts']:.1f} total LLM calls per attempt\")\n",
    "    \n",
    "    # Calculate some efficiency metrics\n",
    "    if perf['total_generations'] > 0:\n",
    "        scoring_ratio = perf['total_scorings'] / perf['total_generations']\n",
    "        print(f\"  Scoring-to-Generation Ratio: {scoring_ratio:.1f}\")\n",
    "        \n",
    "    if result['solved']:\n",
    "        llm_efficiency = result['attempts'] / perf['total_llm_calls']\n",
    "        print(f\"  LLM Efficiency: {llm_efficiency:.3f} attempts per LLM call\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# # Analyze our demo result\n",
    "# # Run a quick test game\n",
    "# demo_result = play_wordle_with_tot(\n",
    "#     target_word=current_word,\n",
    "#     tot_params={\n",
    "#         \"max_depth\": 1,          # Shallow depth for quick demo\n",
    "#         \"threshold\": 0.75,       \n",
    "#         \"high_threshold\": 0.50,  # Lower thresholds for more interesting behavior\n",
    "#         \"retry_threshold\": 0.30, \n",
    "#         \"k\": 2,                  # Generate 2 candidates per round  \n",
    "#         \"beam_size\": 1           # Keep top 1 candidate\n",
    "#     }\n",
    "# )\n",
    "# analyzed_result = analyze_tot_performance(demo_result)\n",
    "\n",
    "# Show how to access the counters programmatically\n",
    "# print(f\"\\nðŸ’» Programmatic Access:\")\n",
    "# print(f\"  result['tot_performance']['total_generations'] = {demo_result['tot_performance']['total_generations']}\")\n",
    "# print(f\"  result['tot_performance']['total_scorings'] = {demo_result['tot_performance']['total_scorings']}\")\n",
    "# print(f\"  result['tot_performance']['total_llm_calls'] = {demo_result['tot_performance']['total_llm_calls']}\")\n",
    "\n",
    "# print(f\"\\nâœ¨ Performance tracking is now fully integrated!\")\n",
    "# print(f\"   Every call to play_wordle_with_tot() returns detailed ToT performance metrics.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a7331ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ® INTERACTIVE MODE DEMO - Play Real Wordle with ToT Assistance!\n",
    "\n",
    "def start_interactive_wordle(word_length: int = 5, max_attempts: int = 6):\n",
    "    \"\"\"Start an interactive Wordle session with Tree of Thought assistance\"\"\"\n",
    "    \n",
    "    print(\"ðŸŽ® Welcome to Interactive Tree of Thought Wordle!\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"HOW IT WORKS:\")\n",
    "    print(\"1. ðŸ§  I'll use Tree of Thought to suggest the best word\")\n",
    "    print(\"2. ðŸ“ You enter that word in your actual Wordle game\")\n",
    "    print(\"3. ðŸŽ¯ You tell me the color feedback you received\")\n",
    "    print(\"4. ðŸ”„ We repeat until solved or max attempts reached\")\n",
    "    print()\n",
    "    print(\"FEEDBACK FORMAT:\")\n",
    "    print(\"  â€¢ G or ðŸŸ© = Green (correct letter, correct position)\")\n",
    "    print(\"  â€¢ Y or ðŸŸ¨ = Yellow (correct letter, wrong position)\")\n",
    "    print(\"  â€¢ B or â¬œ = Black/Gray (letter not in word)\")\n",
    "    print(\"  â€¢ Examples: 'GYBGG', 'ðŸŸ©ðŸŸ¨â¬œðŸŸ©ðŸŸ©', 'green yellow black green green'\")\n",
    "    print()\n",
    "    \n",
    "    # Set word length\n",
    "    set_word_length(word_length)\n",
    "    \n",
    "    print(f\"ðŸŽ¯ Ready to play {word_length}-letter Wordle!\")\n",
    "    print(\"ðŸ“± Go to your Wordle game and let's start!\")\n",
    "    \n",
    "    # Ask user if they're ready\n",
    "    ready = input(\"\\nAre you ready to start? (y/n): \").strip().lower()\n",
    "    if ready not in ['y', 'yes']:\n",
    "        print(\"ðŸ‘‹ Come back when you're ready!\")\n",
    "        return None\n",
    "    \n",
    "    # Start the interactive session\n",
    "    return play_wordle_with_tot(\n",
    "        target_word=None,  # No target word in interactive mode\n",
    "        max_attempts=max_attempts,\n",
    "        interactive=True,\n",
    "        tot_params={\n",
    "            \"max_depth\": 5,\n",
    "            \"threshold\": 0.90,\n",
    "            \"high_threshold\": 0.60,\n",
    "            \"retry_threshold\": 0.40,\n",
    "            \"k\": 3,\n",
    "            \"beam_size\": 2\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fba7481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ® Welcome to Interactive Tree of Thought Wordle!\n",
      "==================================================\n",
      "HOW IT WORKS:\n",
      "1. ðŸ§  I'll use Tree of Thought to suggest the best word\n",
      "2. ðŸ“ You enter that word in your actual Wordle game\n",
      "3. ðŸŽ¯ You tell me the color feedback you received\n",
      "4. ðŸ”„ We repeat until solved or max attempts reached\n",
      "\n",
      "FEEDBACK FORMAT:\n",
      "  â€¢ G or ðŸŸ© = Green (correct letter, correct position)\n",
      "  â€¢ Y or ðŸŸ¨ = Yellow (correct letter, wrong position)\n",
      "  â€¢ B or â¬œ = Black/Gray (letter not in word)\n",
      "  â€¢ Examples: 'GYBGG', 'ðŸŸ©ðŸŸ¨â¬œðŸŸ©ðŸŸ©', 'green yellow black green green'\n",
      "\n",
      "ðŸ“š Loaded 9979 valid 5-letter words\n",
      "ðŸŽ¯ Switched to 5-letter Wordle mode!\n",
      "   Available words: 9979\n",
      "   Suggested starters: []\n",
      "ðŸŽ¯ Ready to play 5-letter Wordle!\n",
      "ðŸ“± Go to your Wordle game and let's start!\n",
      "ðŸŽ® Starting INTERACTIVE Wordle session!\n",
      "ðŸ’¡ I'll suggest words using Tree of Thought, you provide the feedback!\n",
      "ðŸŽ¯ Word length: 5 letters\n",
      "==================================================\n",
      "\n",
      "ðŸ“ Attempt 1/6\n",
      "Previous guesses: \n",
      "\n",
      "ðŸ§  Using Tree of Thought to find next word...\n",
      "Expanding with seed: None\n",
      "GAME HISTORY:  No previous guesses.\n",
      "Generating 3 word candidates for game with 0 attempts\n",
      "Word length: 5\n",
      "Generated candidates: ['crane', 'slate', 'arise']\n",
      "Scoring 3 candidates\n",
      "LLM Reasoning: The guess 'crane' is highly effective as a starting word. It contains four of the top 10 most common letters in Wordle solutions (C, R, A, N, E) and includes two high-frequency vowels (A, E). The letters are all unique, maximizing information gain by testing multiple common characters simultaneously. C is less frequent than some alternatives but still relevant, and E's placement at the end aligns with its common usage. Compared to top-tier starters like 'stare' or 'trace,' 'crane' sacrifices S or T (higher-frequency consonants) for N but retains strong elimination potential. It provides balanced coverage for narrowing down possibilities in both vowels and middle/high-frequency consonants.\n",
      "  crane: 0.90 (excellent)\n",
      "LLM Reasoning: Starting Wordle strategy. High frequency vowels and consonants. Elimination potential. Positional value.\n",
      "  slate: 0.90 (excellent)\n",
      "LLM Reasoning: The word 'arise' is a strong first guess in Wordle because it includes common vowels (a, i, e) and consonants (r, s) that are frequently found in English words. By using 'arise', a player can quickly identify which of the more common letters are present in the target word. The placement of the vowels in different positions can give information on where they occur in the word, which is useful for narrowing down possibilities. Additionally, the letter 's' is a common starting letter and checking it in the fourth position along with other common letters can provide valuable feedback for subsequent guesses.\n",
      "  arise: 0.90 (excellent)\n",
      "ðŸ“Š Performed 3 scoring operations\n",
      "âœ… Normal pruning: 2 high-quality candidates above 0.60\n",
      "   Selected: [('crane', '0.90'), ('slate', '0.90')]\n",
      "Terminating: Found high-quality solution: crane (score: 0.90)\n",
      "ðŸ“Š Attempt 1 ToT stats: 1 generations, 3 scorings\n",
      "ðŸŽ¯ ToT selected: 'CRANE' (score: 0.90)\n",
      "ðŸ’­ Reasoning: The guess 'crane' is highly effective as a starting word. It contains four of the top 10 most common...\n",
      "\n",
      "ðŸŽ¯ You guessed: 'CRANE'\n",
      "Please enter the feedback you received from the actual Wordle game.\n",
      "Enter 5 characters using:\n",
      "  G or ðŸŸ© = Green (correct letter, correct position)\n",
      "  Y or ðŸŸ¨ = Yellow (correct letter, wrong position)\n",
      "  B or â¬œ = Black/Gray (letter not in word)\n",
      "Examples: 'GYBGG', 'ðŸŸ©ðŸŸ¨â¬œðŸŸ©ðŸŸ©', 'green yellow black green green'\n",
      "ðŸ’¡ Or type free text like 'not valid', 'invalid word', 'not accepted' if the word wasn't accepted\n",
      "âœ… Parsed feedback: câ¬œrðŸŸ©aâ¬œnâ¬œeâ¬œ\n",
      "\n",
      "ðŸ“ Attempt 2/6\n",
      "Previous guesses: crane\n",
      "\n",
      "ðŸ§  Using Tree of Thought to find next word...\n",
      "Expanding with seed: None\n",
      "GAME HISTORY:  Guess: CRANE â†’ câ¬œrðŸŸ©aâ¬œnâ¬œeâ¬œ\n",
      "Generating 3 word candidates for game with 1 attempts\n",
      "Word length: 5\n",
      "Generated candidates: ['FROST', 'PROWL', 'BRUSH']\n",
      "Scoring 3 candidates\n",
      "LLM Reasoning: FROST is an effective next guess in this context. It tests four previously untried letters (F, O, S, T) while maintaining R (a known green letter) in position 2. These letters have high elimination potential: S and T are common Wordle letters, and O (a vowel) addresses limited untested vowel options (remaining after A and E were gray). The positions of S and T (positions 4-5) align with their frequent usage in English endings. While R in position 2 is redundant (giving no new info), the word efficiently balances coverage of high-frequency letters with maximal information gain about untested letters. If all new letters are gray, this eliminates four major candidates, drastically narrowing possibilities; if any are green/yellow, it provides clear directional feedback. This strategy optimizes for information gain and elimination efficiency despite partial redundancy.\n",
      "  FROST: 0.87 (excellent)\n",
      "LLM Reasoning: The guess 'PROWL' tests four new letters (P, O, W, L) alongside the known green R. O is a critical vowel, and L/W are moderately frequent consonants. While P is lower-frequency, the diversity and elimination potential are strong: a single gray result would eliminate three consonants, while any yellows or greens significantly narrow possibilities. The position of O in the middle and L at the end could help pin down high-value slots. It outperforms repetitive/low-info guesses but leaves room for even higher-frequency options like 'FROST' (if S/T were tested).\n",
      "  PROWL: 0.85 (excellent)\n",
      "LLM Reasoning: ...\n",
      "  BRUSH: 0.85 (excellent)\n",
      "ðŸ“Š Performed 3 scoring operations\n",
      "âœ… Normal pruning: 2 high-quality candidates above 0.60\n",
      "   Selected: [('FROST', '0.87'), ('PROWL', '0.85')]\n",
      "Continuing to depth 4 with 2 candidates\n",
      "Expanding with seed: ScoredWordCandidate(word='FROST', reasoning=\"The known letters and grayed-out letters restrict the possible solution to 5-letter words with 'R' as the second letter and not containing 'C, A, E, N'. To maximize information gain, the guesses should prioritize untested high-frequency letters (D, F, G, H, I, J, K, L, O, P, Q, S, T, U, V, W, X, Y, Z) and spread them across positions to test both consonants and vowels while avoiding redundancy. 'FROST', 'PROWL', and 'BRUSH' cover 11 unique untested letters (F, O, S, T, P, W, L, B, U, H) while adhering to constraints, making them optimal for narrowing possibilities quickly.\", score=0.87, llm_reasoning='FROST is an effective next guess in this context. It tests four previously untried letters (F, O, S, T) while maintaining R (a known green letter) in position 2. These letters have high elimination potential: S and T are common Wordle letters, and O (a vowel) addresses limited untested vowel options (remaining after A and E were gray). The positions of S and T (positions 4-5) align with their frequent usage in English endings. While R in position 2 is redundant (giving no new info), the word efficiently balances coverage of high-frequency letters with maximal information gain about untested letters. If all new letters are gray, this eliminates four major candidates, drastically narrowing possibilities; if any are green/yellow, it provides clear directional feedback. This strategy optimizes for information gain and elimination efficiency despite partial redundancy.', bucket='excellent')\n",
      "GAME HISTORY:  Guess: CRANE â†’ câ¬œrðŸŸ©aâ¬œnâ¬œeâ¬œ\n",
      "Generating 3 word candidates for game with 1 attempts\n",
      "Word length: 5\n",
      "Expanding with seed: ScoredWordCandidate(word='PROWL', reasoning=\"The known letters and grayed-out letters restrict the possible solution to 5-letter words with 'R' as the second letter and not containing 'C, A, E, N'. To maximize information gain, the guesses should prioritize untested high-frequency letters (D, F, G, H, I, J, K, L, O, P, Q, S, T, U, V, W, X, Y, Z) and spread them across positions to test both consonants and vowels while avoiding redundancy. 'FROST', 'PROWL', and 'BRUSH' cover 11 unique untested letters (F, O, S, T, P, W, L, B, U, H) while adhering to constraints, making them optimal for narrowing possibilities quickly.\", score=0.85, llm_reasoning=\"The guess 'PROWL' tests four new letters (P, O, W, L) alongside the known green R. O is a critical vowel, and L/W are moderately frequent consonants. While P is lower-frequency, the diversity and elimination potential are strong: a single gray result would eliminate three consonants, while any yellows or greens significantly narrow possibilities. The position of O in the middle and L at the end could help pin down high-value slots. It outperforms repetitive/low-info guesses but leaves room for even higher-frequency options like 'FROST' (if S/T were tested).\", bucket='excellent')\n",
      "GAME HISTORY:  Guess: CRANE â†’ câ¬œrðŸŸ©aâ¬œnâ¬œeâ¬œ\n",
      "Generating 3 word candidates for game with 1 attempts\n",
      "Word length: 5\n",
      "Generated candidates: ['GROST', 'BRUSH', 'TROYS']\n",
      "Generated candidates: ['TRIOL', 'DROPS', 'BROTH']\n",
      "Scoring 3 candidates\n",
      "LLM Reasoning: ...\n",
      "  TRIOL: 0.47 (ok)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     23\u001b[39m word_generator = generation_prompt | llm.with_structured_output(GuessWords)\n\u001b[32m     24\u001b[39m word_scorer = scoring_prompt | llm.with_structured_output(WordleScoring)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[43mstart_interactive_wordle\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mstart_interactive_wordle\u001b[39m\u001b[34m(word_length, max_attempts)\u001b[39m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Start the interactive session\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mplay_wordle_with_tot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_word\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# No target word in interactive mode\u001b[39;49;00m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_attempts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_attempts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43minteractive\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtot_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_depth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreshold\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.90\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhigh_threshold\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.60\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mretry_threshold\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mk\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbeam_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 70\u001b[39m, in \u001b[36mplay_wordle_with_tot\u001b[39m\u001b[34m(target_word, max_attempts, tot_params, interactive)\u001b[39m\n\u001b[32m     67\u001b[39m attempt_generations = \u001b[32m0\u001b[39m\n\u001b[32m     68\u001b[39m attempt_scorings = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtot_result\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Track generation and scoring counts from each step\u001b[39;49;00m\n\u001b[32m     72\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/langgraph/pregel/main.py:2651\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2649\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2650\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2651\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2654\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2656\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2657\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2658\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2659\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2660\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2661\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/langgraph/pregel/_runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:646\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    644\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    645\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m646\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    648\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:390\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    388\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    392\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 104\u001b[39m, in \u001b[36mscore\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mScoring \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(candidates)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m candidates\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m candidate \u001b[38;5;129;01min\u001b[39;00m candidates:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     scored_candidate = \u001b[43mcompute_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m     scored.append(scored_candidate)\n\u001b[32m    106\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mLLM Reasoning: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscored_candidate.llm_reasoning\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mcompute_score\u001b[39m\u001b[34m(game_state, candidate)\u001b[39m\n\u001b[32m     44\u001b[39m constraints = format_constraints(game_state)\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     scoring_result = \u001b[43mword_scorer\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgame_history\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgame_history\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconstraints\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mattempts\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgame_state\u001b[49m\u001b[43m.\u001b[49m\u001b[43mattempts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mword\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mword_length\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mWORD_MANAGER\u001b[49m\u001b[43m.\u001b[49m\u001b[43mword_length\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_reasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmedium\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m     \u001b[38;5;66;03m# Convert 1-100 score to 0-1 for consistency with existing framework\u001b[39;00m\n\u001b[32m     58\u001b[39m     normalized_score = scoring_result.score / \u001b[32m100.0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/langchain_core/runnables/base.py:3046\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3044\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3045\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3046\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3047\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3048\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/langchain_core/runnables/base.py:5434\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5427\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5428\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5429\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5432\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5433\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5434\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5435\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5436\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5437\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5438\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:395\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    385\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    390\u001b[39m     **kwargs: Any,\n\u001b[32m    391\u001b[39m ) -> BaseMessage:\n\u001b[32m    392\u001b[39m     config = ensure_config(config)\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    394\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    405\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:980\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    971\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    972\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    973\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    977\u001b[39m     **kwargs: Any,\n\u001b[32m    978\u001b[39m ) -> LLMResult:\n\u001b[32m    979\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m980\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:799\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    796\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    797\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    798\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m799\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    805\u001b[39m         )\n\u001b[32m    806\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    807\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1045\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1043\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1044\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1045\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1046\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1047\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1048\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1049\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1104\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1102\u001b[39m payload.pop(\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1103\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1104\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m openai.BadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1106\u001b[39m     _handle_openai_bad_request(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:180\u001b[39m, in \u001b[36mCompletions.parse\u001b[39m\u001b[34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparser\u001b[39m(raw_completion: ChatCompletion) -> ParsedChatCompletion[ResponseFormatT]:\n\u001b[32m    174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[32m    175\u001b[39m         response_format=response_format,\n\u001b[32m    176\u001b[39m         chat_completion=raw_completion,\n\u001b[32m    177\u001b[39m         input_tools=tools,\n\u001b[32m    178\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_type_to_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `ChatCompletion` instance into a `ParsedChatCompletion`\u001b[39;49;00m\n\u001b[32m    226\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[32m    227\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedChatCompletion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py:1256\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1243\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1244\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1251\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1252\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1253\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1254\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1255\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1256\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/openai/_base_client.py:979\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    977\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    978\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    985\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py:928\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    927\u001b[39m     response.close()\n\u001b[32m--> \u001b[39m\u001b[32m928\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py:922\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m922\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    924\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_models.py:881\u001b[39m, in \u001b[36mResponse.read\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    877\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    878\u001b[39m \u001b[33;03mRead and return the response content.\u001b[39;00m\n\u001b[32m    879\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    880\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_content\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m881\u001b[39m     \u001b[38;5;28mself\u001b[39m._content = \u001b[33;43mb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._content\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_models.py:897\u001b[39m, in \u001b[36mResponse.iter_bytes\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    895\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    896\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_models.py:951\u001b[39m, in \u001b[36mResponse.iter_raw\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    948\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m951\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_num_bytes_downloaded\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_client.py:153\u001b[39m, in \u001b[36mBoundSyncStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpx/_transports/default.py:127\u001b[39m, in \u001b[36mResponseStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_httpcore_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:407\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    406\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:403\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/http11.py:342\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[32m    341\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/http11.py:334\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    333\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mreceive_response_body\u001b[39m\u001b[33m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m._request, kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    337\u001b[39m     \u001b[38;5;66;03m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[32m    338\u001b[39m     \u001b[38;5;66;03m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[32m    339\u001b[39m     \u001b[38;5;66;03m# before raising that exception.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/http11.py:203\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_body\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    200\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Data):\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m(event.data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/ssl.py:1233\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1230\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1231\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1232\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1233\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1235\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/ssl.py:1106\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1104\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1105\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1108\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "   # model=\"deepseek/deepseek-r1\",\n",
    "    # model=\"qwen/qwen3-235b-a22b\",\n",
    "    # model=\"anthropic/claude-sonnet-4\",\n",
    "    # model=\"moonshotai/kimi-vl-a3b-thinking\",\n",
    "    # model=\"mistralai/magistral-medium-2506:thinking\",\n",
    "    # model=\"openai/o4-mini\",\n",
    "    \n",
    "MODEL = \"qwen/qwen3-235b-a22b\"\n",
    "llm = ChatOpenAI(\n",
    "    model=MODEL,\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    \n",
    ")\n",
    "scoring_llm = ChatOpenAI(\n",
    "    model=MODEL,\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    ")\n",
    "\n",
    "# Bound LLMs for each task\n",
    "word_generator = generation_prompt | llm.with_structured_output(GuessWords)\n",
    "word_scorer = scoring_prompt | llm.with_structured_output(WordleScoring)\n",
    "\n",
    "\n",
    "start_interactive_wordle(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463eea79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390faf52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7468ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59af7070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f60ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a18d12c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00bf543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2e8fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90afd71b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
